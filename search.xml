<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[小冰架构学习]]></title>
    <url>%2F%E5%B0%8F%E5%86%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[设计思想如何评价小冰Open Domain Social Long-term Dialogue System的性能？ 单次对话论述 Conversation-turns Per Session(CPS)作为评估社交聊天机器人成功的指标。CPS越大，社交聊天机器人的对话参与能力就越好。第六代小冰的CPS已经从第一代的5提升到23。 IQ+EQ+Personality 社交聊天机器人需要足够高的智商（IQ）来学习多种技能，才能紧跟用户需求，帮助他们完成指定任务。同时，社交聊天机器人还需要足够高的情商（EQ），以满足用户情感的需求，比如情绪感受和社会归属感。 IQ：IQ能力包括知识和记忆建模、图像和自然语言理解、推理生成和预测。为了满足用户的特定需求以及帮助用户完成指定的任务，这些能力是不可或缺的。其中最重要且最复杂的技能是核心聊天（Core Chat），即与用户在多个主题上展开长时间和开放域的对话 EQ： Personality：符合小冰既有的风格 将社交聊天视为分层决策 对话可被视为有自然层级的决策过程：一个顶级过程管理者整体的对话并选取不同的技能来处理不同类型 的对话模式（比如闲聊、问答、订票）；低级过程则受所选择的技能控制。可选择基本动作（响应），从而生成对话段落或完成任务。 系统架构 上图为小冰的整体架构，其包含三层：用户体验层、对话引擎层和数据层。 用户体验层对话引擎层对话引擎层中的四个主要组件：对话管理、共情计算、核心聊天和技能。 对话管理对话管理除了记录对话历史还要包括策略管理，即管理什么时候触发Skill什么时候切换。同时，Conversation还受到Topic的管理。在Pretrain的阶段得到Topic Index，当触发Topic切换的标志时，例如： Core Chat未能生成有效的候选集 生成的响应知识用户输入的重复 用户输入变得平淡 则调用Topic切换，切换之后的Topic根据以下几个指标选取： 上下文关联性 新鲜度 个人兴趣 热度 接受度 共情计算（Empathetic Computing）共情度计算是小冰相对独特的一点，它不是直接把Context和Reply进行匹配得到一个Match Score。而是由Query, Context, Reply及情景分析得到一个$s=\left(Q_{c}, C, e_{Q}, e_{R}\right)$向量，再由向量$s$计算出候选回复。 Contextual Query Understanding 本模块的主要任务是对Context进行补全，通过命名实体识别和指代消解的方法，对对话历史信息进行补全。 User Understand Interpersonal Response Generation 核心聊天（Core chat）小冰在处理语言生成的时候使用两阶段法，先构造Reply候选集，然后通过计算每个Reply的得分（Score）选出最优答案。 Retrieval-Based Using Paired Data Neural Generate 单纯靠检索来获得数据，会漏掉一些新的热点，覆盖面不高。在小冰的架构中，对前面构造的向量$s$做sigmoid操作$v=\sigma\left(W_{Q}^{T} e_{Q}+W_{R}^{T} e_{R}\right)$，每一轮都喂到网络中这样保证了生成的Response带有小冰的人格。 Retrieval-Based Using Unpaired Data Rank 数据层 参考直男届的杀手-『小冰』架构解析 沈向洋等人论文详解微软小冰，公开研发细节 The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Li Zhou et al. 18.12]]></content>
  </entry>
  <entry>
    <title><![CDATA[《通过对响应原型编辑的回复生成》阅读笔记]]></title>
    <url>%2F%E3%80%8A%E9%80%9A%E8%BF%87%E5%AF%B9%E5%93%8D%E5%BA%94%E5%8E%9F%E5%9E%8B%E7%BC%96%E8%BE%91%E7%9A%84%E5%9B%9E%E5%A4%8D%E7%94%9F%E6%88%90%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[论文题目：Response Generation by Context-aware Prototype Editing 代码链接：https://github.com/MarkWuNLP/ResponseEdit AAAI 2019 北航 本文的主要目的是为了解决开放域对话生成中，生成句子较短且无意义的问题。模型首先从预定义的索引中检索到响应，然后根据问题原型和当前问题的差异编辑响应原型。主要思想是基于由于响应原型有很好的语法和信息，对响应原型进行轻微地调整就能得到较好的回复这一假设，来进行相关实验和论证。这是一种“检索+生成”的方法，既有检索式聊天机器人回复流畅和信息量大的优势，还有生成式聊天机器人的灵活性和相关性。 模型该模型由原型选择器$\mathcal{S}$和上下文感知编辑器$\mathcal{E}$组成。给定一个新的会话，我们首先使用选择器S来检索语料$\mathcal{D} = {(C_i, R_i)}_{i=1}^{N}$中的$(C_{i}, R_{i}) \in \mathcal{D}$。然后编辑器$\mathcal{E}$计算出$z_i = f(C_i, C)$来编码$C_i$和$C$之间的差异信息。最后，通过概率$p(R|z_i, R_i)$生成回复。 原型选择器(Prototype Selector) 原型选择器使用Lucene框架用于检索，并应用其内置算法计算相似度。 测试阶段 根据上下文$C$与语料中$C^{‘}$的相似性选出（$C^{‘}$ , $R^{‘}$） 训练阶段 由于有真实的response，训练阶段的$C$，$R$对是通过response之间的相似性中选出来的。使用Jaccard相似度，取出范围在0.3-0.7的结果。这样既过滤掉相似度小于0.3的不相关回复，又除去相似度大于0.7的回复，避免直接copy。 Jaccard相似系数 J(A, B) = \frac{|A \cap B|}{|A \cup B|}在这个阶段最终得到多个四元组$(C, R, C^{‘}, R^{‘})$ 上下文感知编辑器（Context-Aware Neural Editor）Edit Vector Generation 该部分的主要功能是根据$C$和$C^{‘}$的差异生成编辑向量（edit vector） 用biGRU对$R^{‘}$进行编码 \overrightarrow{h_j} = f_{GRU}(h_{j-1}, r_{j}^{'}); \overleftarrow{h_j} = f_{GRU}(h_{j+1}, r_{j}^{'})用attention机制计算context之间的diff-vector，其中$I=\{w | w \in C \land w \notin C^{‘}\}$表示插入词集合，$I=\{D | w^{‘} \in C^{‘} \land w^{‘} \notin C \}$表示删除词集合，$\oplus$表示concat操作。 diff_{c} = \sum_{w \in I} \beta_w \Psi(w) \oplus \sum_{w^{'} \in D} \gamma_{w^{'}} \Psi(w^{'}) \beta_w = \frac{exp(e_w)}{\sum_{w \in I}exp(e_w)} e_w = v_{\beta}^{T}tanh(W_{\beta}[\Psi(w)\oplus h_l]) \gamma_{w^{'}} = \frac{exp(e_{w^{'}})}{\sum_{w \in I}exp(e_{w^{'}})} z = tanh(W \cdot diff_{c} + b)Prototype Editing 该部分将编辑向量（edit vector）集成到decoder中进行输出 h_{j}^{\prime}=f_{\mathrm{GRU}}\left(h_{j-1}^{\prime}, r_{j-1} \oplus z_{i}\right) c_{i}=\sum_{j=1}^{t} \alpha_{i, j} h_{j} \begin{aligned} \alpha_{i, j} &=\frac{\exp \left(e_{i, j}\right)}{\sum_{k=1}^{t} \exp \left(e_{i, k}\right)} \\ e_{i, j} &=\mathbf{v}^{\top} \tanh \left(\mathbf{W}_{\alpha}\left[h_{j} \oplus h_{i}^{\prime}\right]\right) \end{aligned} s\left(r_{i}\right)=\operatorname{softmax}\left(\mathbf{W}_{\mathbf{p}}\left[r_{i-1} \oplus h_{i}^{\prime} \oplus c_{i}\right]+\mathbf{b}_{\mathbf{p}}\right)目标函数 \mathcal{L} = - \sum_{i=1}^N\sum_{j=1}^{l}log p(r_{i,j}|z_i, R_{i}^{'}, r_i, k]]></content>
      <categories>
        <category>NLP</category>
        <category>NLG</category>
      </categories>
      <tags>
        <tag>dialogue system</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文NLSQL挑战赛]]></title>
    <url>%2F%E4%B8%AD%E6%96%87NLSQL%E6%8C%91%E6%88%98%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[比赛官网：https://tianchi.aliyun.com/competition/entrance/231716/information 竞赛题目首届中文NLSQL挑战赛，使用金融以及通用领域的表格作为数据源，提供在此基础上标注的自然语言与SQL语句的匹配对，目的是设计模型准确将自然语言转换成SQL。 数据模型本次赛题提供4w条有标签数据作为训练集，1w条无标签数据作为测试集。其中，5千条测试集作为初赛测试集（对选手可见）；另外5千条作为复赛测试集（对选手不可见）。提供的数据集主要由3个文件组成，以训练集为例，包括train.json、train.tables.json及train.db。数据中每一个样本都对应着一个数据表，里面包含该表所有列名，以及相应的数据记录。原则上生成的SQL语句在对应的数据表上是可以执行的，并且都能返回有效的结果。 train.json 12345678910111213&#123; "table_id": "a1b2c3d4", # 相应表格的id "question": "世茂茂悦府新盘容积率大于1，请问它的套均面积是多少？", # 自然语言问句 "sql":&#123; # 真实SQL "sel": [7], # SQL选择的列 "agg": [0], # 选择的列相应的聚合函数, '0'代表无 "cond_conn_op": 0, # 条件之间的关系 "conds": [ [1,2,"世茂茂悦府"], # 条件列, 条件类型, 条件值，col_1 == "世茂茂悦府" [6,0,1] ] &#125;&#125; 其中，SQL的表达字典说明如下： 123op_sql_dict = &#123;0:"&gt;", 1:"&lt;", 2:"==", 3:"!="&#125;agg_sql_dict = &#123;0:"", 1:"AVG", 2:"MAX", 3:"MIN", 4:"COUNT", 5:"SUM"&#125;conn_sql_dict = &#123;0:"", 1:"and", 2:"or"&#125; 主办方已经将SQL语句做了十分清晰的格式化，比如sel这个字段，其实就是一个多标签分类模型，只不过类别可能会随时变化。agg则跟sel是一一对应的，并且类别是固定的，cond_conn_op则是一个单标签分类问题。 train.tables.json 12345678910111213141516171819202122&#123; "id":"a1b2c3d4", # 表格id "name":"Table_a1b2c3d4", # 表格名称 "title":"表1：2019年新开工预测 ", # 表格标题 "header":[ # 表格所包含的列名 "300城市土地出让", "规划建筑面积(万㎡)", …… ], "types":[ # 表格列所相应的类型 "text", "real", …… ], "rows":[ # 表格每一行所存储的值 [ "2009年7月-2010年6月", 168212.4, …… ] ]&#125; tables.db为sqlite格式的数据库形式的表格文件。各个表的表名为tables.json中相应表格的name字段。为避免部分列名中的特殊符号导致无法存入数据库文件，表格中的列名为经过归一化的字段，col_1, col_2, …, col_n。 baselineSQLNet 该模型将生成整个SQL的任务分解为多个子任务，包括select-number，选择哪一列select-column，使用什么聚合函数select-aggregation，有几个条件condition-number，筛选条件针对哪几列condition-column等。 paper：https://arxiv.org/pdf/1711.04436.pdf code：https://github.com/xiaojunxu/SQLNet 该模型使用sketch-based方法，来解决“order-matters”的问题。根据数据集中的数据特征以及编写SQL时的先后顺序，各个子任务之间存在如下图所示的依赖关系。这样的依赖关系可以一定程度上利用已预测好的任务来帮助下游任务更好地预测。 sequence to set由于出现在WHERE子句中的列名构成了所有列名集合的子集，因此得到where-column的预测概率如下： P_{\text { wherecol }}(\operatorname{col} | Q)=\sigma\left(u_{c}^{T} E_{c o l}+u_{q}^{T} E_{Q}\right)其中$\sigma$是sigmoid激活函数，$E_{c o l}$和$E_{Q}$分别是列名和Query的embedding。 column attentionOP slotVALUE slot感觉”木桶效应“的短板就在这里了 {P_{\mathrm{val}}(i | Q, c o l, h)=\operatorname{softmax}(a(h))} \\ {a(h)_{i}=\left(u^{\mathrm{val}}\right)^{T} \tanh \left(U_{1}^{\mathrm{val}} H_{Q}^{i}+U_{2}^{\mathrm{val}} E_{c o l}+U_{3}^{\mathrm{val}} h\right) \quad \forall i \in\{1, \ldots, L\}}SQLovaSQLova 是韩国 Naver 提出的一种模型，全名为 Search &amp; QLova，是作者们所在部门的名称。此方案是于 SQLNet 的基础上，在模型结构方面做了一些改进而得到的，并没有提出一些创新性的解决方案。 SQLova 使用了 BERT 来作为模型的输入表达层，代替了词向量。为了让自然语言问句与表结构更好地结合，模型将自然语言问句与列名一并作为输入进行编码。同时，模型在拼接输入时采用了不同的 Segmentation Embedding 来让 BERT 可以区分问题和列名。 X-SQLX-SQL 是微软 Dynamics 365 提出一种方案。这个方案同样继承了解耦任务的思路，将预测 SQL 分解为 6 个子任务。但不同于 SQLova，X-SQL 引入了更多创新性的一些改进，主要包括以下几个方面。 首先，X-SQL 使用了 MT-DNN 来作为编码层，代替了 SQLova 中使用的 BERT，因为 MT-DNN 在很多其它自然语言处理的下游任务上取得了比 BERT 更好的效果。但因为作者并没有提供对比实验，所以 MT-DNN 可以比 BERT 带来多少的提升就不得而知。 其次，X-SQL 在 SQLova 中原有的 Question Segmentation 和 Column Segmentation 的基础上拓展为 Question、Categorical Column、Numerical Column 以及 Empty Column 这四种 Segmentation Embedding，分别用来作为自然语言问句、文本类型的列、数字类型的列以及空列的相应输入。通过引入更多的分类表达，可以让模型得以区分数字与文本类型的列，进而更好地生成 SQL。 最后，在输出层与损失函数部分，Where-Column 的损失函数被定义为了 KL 散度。并且，借助之前提到的引入的特殊列 [EMPTY]，如果模型在预测 Where-Column 时，分数最高的列是 [EMPTY]，那么就无视 Where-Number 所得到的预测结果，判断 SQL 语句为没有条件。 通过这些输入与结构上的优化，X-SQL 可以在 WikiSQL 的测试集上取得 86.0% 的 Logic Form 准确率和 91.8% 的 Execution 准确率。 苏剑林老师基于BERT的baseline 代码：https://github.com/bojone/bert_in_keras/blob/master/nl2sql_baseline.py 评价标准Logic Form Accuracy: 预测完全正确的SQL语句。其中，列的顺序并不影响准确率的计算。Execution Accuracy: 预测的SQL的执行结果与真实SQL的执行结果一致。 计算公式如下： Score_{l f}=\left\{\begin{array}{ll}{1,} & {S Q L^{\prime}=S Q L} \\ {0,} & {S Q L^{\prime} \neq S Q L}\end{array}\right. A c c_{l f}=\frac{1}{N} \sum_{n=1}^{N} S c o r e_{l f}^{n} Score_{e x}=\left\{\begin{array}{ll}{1,} & {Y^{\prime}=Y} \\ {0,} & {Y^{\prime} \neq Y}\end{array}\right. A c c_{e x}=\frac{1}{N} \sum_{n=1}^{N} S c o r e_{e x}^{n}最后线上的评估指标为（Logic Form Accuracy + Execution Accuracy）/ 2 其他相似任务WikiSQL数据集提供了8w多条有标签数据，足以满足目前的数据驱动型算法对数据量的需求。目前榜单上，效果最好的模型是SQLova和X-SQL，它们在测试集上分别可以达到89.6%和91.8%的执行准确率。 参考NL2SQL：弱监督学习与有监督学习完成进阶之路 SQLNet——知乎 基于Bert的NL2SQL模型：一个简明的Baseline]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于 Hexo + Github Pages 搭建个人博客]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8E%20Hexo%20%2B%20Github%20Pages%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[准备知识什么是Github Pages?什么是Hexo？Hexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown解析文章，在几秒内，即可使用靓丽的主题生成静态网页。 搭建步骤环境 Ubuntu 16.04 git Node.js：建议使用nvm进行安装 123wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bashnvm install stable 安装Hexo官方安装文档 1$ npm install hexo-cli -g 在本地第一次部署1234$ hexo init blog$ cd blog$ hexo generate$ hexo server 现在在浏览器中输入localhost:4000 public: 执行hexo generate命令，输出的静态网页内容目录 scaffolds: layout模板文件目录 scripts： 扩展脚本目录，这里可以自定义一些javascript脚本 source： 文章源码目录，该目录下的markdown和html文件均会被hexo处理 drafts: 保存草稿文章 posts: _config.yml: 网站的全局配置文件 package.json: hexo的版本信息 使用Next主题在Hexo中有两份主要的配置文件，其名称都是_config.yml。其中一份位于站点根目录下，主要包含Hexo本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。为了区分，我们将前者称为站点配置文件，后者称为主题配置文件。 下载Next主题1234$ git clone https://github.com/iissnan/hexo-theme-next themes/next``` 修改主目录下的_config.yml配置文件 theme: next12在本地测试网站 $ hexo clean$ hexo generate$ hexo server``` 参考Github Pages+Hexo搭建个人博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[《情感对话生成》阅读笔记]]></title>
    <url>%2F%E3%80%8AEmotional%20Chatting%20Machine%20Emotional%20Conversation%20Generation%20with%20Internal%E3%80%8B%2F</url>
    <content type="text"><![CDATA[论文题目：Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory 论文链接：https://arxiv.org/abs/1704.01074 代码链接：https://github.com/tuxchow/ecm AAAI 2019 Introduction朱小燕、黄民烈老师团队发布的论文「 Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory」首次将情感因素引入了基于深度学习的生成式对话系统，提出了基于记忆网络的情感对话系统 Emotional Chatting Machine (ECM) ，在传统的 Sequence to Sequence 模型的基础上，ECM 使用了静态的情感向量嵌入表示，动态的情感状态记忆网络和情感词外部记忆的机制，使得 ECM 可以根据用户的输入以及指定情感分类输出相应情感的回复语句。 代码链接：https://github.com/tuxchow/ecm 本文用输入作为一种提示和期望的情感的反应，来产生一个回答，采用NLPCC数据集训练一个情感分类器，利用分类器对大规模的对话数据进行自动标注，划分了六类情感，怒、厌恶、快乐、喜欢、悲伤和其他，并用三元数据向量（posts，responses, emotion labels of responses)训练ECM模型。本文设计了一个ECM（Emotional Chatting Machine）框架的，基于记忆网络memory的具有情感生成机制的seq2seq编解码生成模型，模型利用GRU进行编解码。 Model 模型的总体框架如上图所示，用户问题输入为“What a lovely day!”，通过 Encoder 将其编码为隐向量表示 h，然后通过注意力机制，结合 decoder 的状态向量 $s$ 在生成不同的词时，对问题的隐向量表示 h 的不同部分的信息选择性的加强，得到向量 $c$。指定情感类别为“Happiness”，经过索引得到情感类别嵌入向量，初始的情感状态记忆向量和相应的情感词表。decoder 接受经过注意力机制的问题向量 $c$，情感类别嵌入向量和初始的情感状态记忆向量作为输入，通过循环神经网络生成下个词的生成概率 o，之后再经过情感词表对情感词和非情感词的加权，得到最终词的生成概率，通过采样即可得到输出“Haha, so happy today!”。 Encoder-Decoder-Attn框架 编码器将输入序列$X=(x_1,x_2,…, x_n)$转化为隐层表示$h=(h_1,h_2,…, h_n)$: h_t = GRU(h_{t-1}, x_t)解码器将上下文向量（context vector）$c_t$和上一个已解码的词向量$e(y_{t-1})$作为输入，使用另一个GRU来更新隐层状态： s_t = GRU(s_{t-1},[c_t;e(y_{t-1})])$[c_t;e(y_{t-1})]$是两个向量的级联，在我们得到隐层向量$s_t$之后，解码器通过计算得到输出概率分布$o_t$生成新的词： y_t o_t = P(y_t|y_1,y_2,...,y_{t-1},c_t) = softmax(W_os_t)Emotional Category Embedding将情感的类别编码成低维度的向量，然后将情感向量$v_e$、向量$e(y_{t-1})$和上下文向量$c_t$合并到一起作为解码器的输入更新解码器的隐层状态$s_t$： s_{t}=GRU(s_{t-1}, [c_t;e(y_{t-1});v_e])Internal MemoryAffect-lm模型论文中提到简单的情感向量嵌入的方式会影响句子语法的准确性。因此，本文设计了一个内部记忆模块在解码时捕捉情感的动态变化。 本模块受到Annotating and modeling empathy in spoken conversations这篇论文启发，具体结构如上图。在每个时间步都会计算Read Gate $g_t^r$和Write Gate $g_t^r$： g_t^r = sigmoid(W_g^r[e(y_{t-1});s_{t-1};c_t]) g_t^w = sigmoid(W_g^w[e(s_t])$g_t^r$和$g_t^w$是用来对内部记忆模块进行读写操作的。这样每一个时间步,情感状态都会被$g_t^w$消除一部分，这与Key-value memory networks中DELETE操作十分相似。在最后一步时内部的情感信息会被减少至0，表示情感已经被全部表达。 M_{r,t}^I = g_t^r \bigotimes M_{e,t}^I M_{r,t+1}^I = g_t^w \bigotimes M_{e,t}^I s_t = GRU(s_{t-1}, [c_t;e(y_{t-1};M_{e,t}^I)])External Memory针对不同的词汇所表达的感情，模型使用External Memory模块来建模显式的情感表达，给情感词汇和普通词汇赋予不同的生成概率。因此，模型可以选择从情感词汇和普通词汇中选择生成一个词。 \alpha_t = sigmoid(v_u^T s_t) P_g(y_t=w_g) = softmax(W_g^o s_t) P_e(y_t=w_e) = softmax(W_e^o s_t) y_t o_t =P(y_t) = \alpha_t P_e(y_t=w_e) + (1-\alpha_t) P_y(y_t=w_g)损失函数 L(\theta) = - \sum_{t=1}^{m} p_t log(o_t) - \sum_{t=1}^{m} q_tlog(\alpha_t) + ||M_{e,m}^{I}||数据集数据集：NLPCC2017 Shared Task 4 情感分类数据集：NLPCC20132 and NLPCC20143（中文数据）The taxonomy comes from http://tcci.ccf.org.cn/confere-nce/2014/dldoc/evatask1.pdf 大连理工的情感词汇数据集：http://ir.dlut.edu.cn/news/detail/215 主要参考文献 [Ghosh et al. 2017] Ghosh, S.; Chollet, M.; Laksana, E.;Morency, L.; and Scherer, S. 2017. Affect-lm: A neurallanguage model for customizable affective text generation.In ACL, 634–642. [Alam, Danieli, and Riccardi 2017] Alam, F.; Danieli, M.;and Riccardi, G. 2017. Annotating and modeling empathyin spoken conversations. CoRR abs/1705.04839. [Miller et al. 2016] Miller, A. H.; Fisch, A.; Dodge, J.;Karimi, A.; Bordes, A.; and Weston, J. 2016. Keyvaluememory networks for directly reading documents. InEMNLP, 1400–1409.]]></content>
  </entry>
  <entry>
    <title><![CDATA[知识驱动的对话生成]]></title>
    <url>%2F%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E5%AF%B9%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[该任务是基于2019年语言与智能竞赛，知识驱动对话赛道。当前聊天机器人不够主动，并且回复信息不够丰富。 任务给定目标 $g$ 及相关知识信息 $M=f_1, f_2, …, f_n$ ，要求参评的对话系统输出适用于当前新对话序列 $H=u_1, u_2,…,u_{t-1}$ 的机器回复$u_t$使得对话自然流畅、信息丰富而且符合对话目标的规划。在对话过程中，机器处于主动状态，引导用户从一个话题聊到另一个话题。因此，对话系统为机器设定了一个对话目标，$g$为“START-&gt;TOPIC_A-&gt;TOPIC_B”，表示从冷启动状态主动聊到话题A，然后进一步聊到话题B。 比赛数据数据中的知识信息来源于电影和娱乐人物领域有价值的信息，如票房、导演、评价等，以三元组SPO的形式组织。对话目标中的话题为电影或娱乐人物实体，数据集中共有3万session，大约12万轮对话，其中10万训练集，1万开发集，1万测试集。 基线模型该模型主要由四部分组成，分别为对话内容编码器、知识编码器、知识管理器和解码器。 paper: https://arxiv.org/abs/1902.04911 code: https://github.com/baidu/knowledge-driven-dialogue Encoder在这部分，模型使用双向GRU来对对话内容和知识进行编码。我们定义$X$为多轮对话内容，$K$为知识库信息，$Y$为真实的回复。编码器将对话内容 $X$ 和知识信息 $K$ 编码成向量 $x$ 和 $k$，之后送入Knowledge manager。编码对话内容和知识信息的两个编码器遵循同样的结构，但不共享参数。 h_t =[\overrightarrow{h}_t ; \overleftarrow{h}_t]=[GRU(x_t, \overrightarrow{h}_{t-1});GRU(x_t, \overleftarrow{h}_{t+1})]Knowledge Manager知识管理模块这部分的作用主要为从外部知识中选出所需知识。在训练过程中，X和Y均被模型作为输入进行训练。这是通过后验信息得到知识的概率分布，计算公式如下： p(k=k_i |x,y)=\frac{exp(k_i \cdot MLP([x;y]))}{\sum_{j=1}^{N} exp(ki \cdot MLP([x;y]))}但在生成预测回复的时候，$Y$对于我们来说是未知的，所以我们只能通过输入$X$来进行知识选择。具体公式如下： p(k=k_i|x)=\frac{exp(k_i \cdot x)}{\sum_{j=1}^N exp(k_j \cdot x)}在训练和预测回复的过程中，选择知识$k$分别是依据后验概率$p(k|x,y)$和$p(k|x)$。因此知识管理模块采用KLDivLoss（KullbackLeibler divergence loss）作为损失函数来衡量先验和后验的相似性。 \mathcal{L}_{KL}(\theta)=-\frac{1}{N}\sum_{i=1}^{N}p(k=k_i|x,y)log\frac{p(k=k_i|x,y)}{p(k=k_i|x)}Knowledge ManagerDecoder在上下文内容$c_t$和所选择的$k_i$的条件下，模型的解码器按顺序生成回复。与传统的Seq2Seq解码器不同，该模型将知识融入到回复生成中。因此，模型中介绍两种解码器。 Standard GRU with Concatenated Inputs $s_{t-1}$是GRU的上一步隐层状态，$c_t$是基于attention的上下文向量。 s_t = GRU([y_{t-1};k_i], s_{t-1}, c_t)Hierarchical Gated Fusion Unit HGFU(Hierarchical Gated Fusion Unit)的中文是分级门控融合单元，其提供了一个相对较“软”的方法将Knowledge合并到回复当中。它主要由3部分组成：utterance GRU、knowledge GRU和fusion unit。 utterance GRU和knowledge GRU这两部分，均使用标准的GRU结构： s_t^y = GRU(y_{t-1}, s_{t-1}, c_t) s_t^k = GRU(k_{i}, s_{t-1}, c_t)然后fusion unit将两个隐藏层合并起来生成解码器$t$时刻的隐藏状态。 s_t = r \odot s_t^y + (1-r)\odot s_t^k其中，$r$控制着隐层状态$s_t$的分布 r = \sigma(W_z[tanh(W_y s_t^y);tanh(W_k s_t^k)])Loss 函数除了KLDivLoss以外，模型中的loss函数还包括NLL Loss和BOW Loss。其中，NLL Loss的作用是最小化生成回复与原始回复之间的差异： \mathcal{L}_{NLL}(\theta)=-\frac{1}{m} \sum_{t=1}^{m} log p_{\theta}(y_t|y]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
