<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sherlockの小酒馆</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.sherlocknlp.com/"/>
  <updated>2019-09-15T13:24:27.839Z</updated>
  <id>http://www.sherlocknlp.com/</id>
  
  <author>
    <name>Sherlock</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《基于主题模板和结构化卷积解码器生成摘要》阅读笔记</title>
    <link href="http://www.sherlocknlp.com/%E3%80%8A%E5%9F%BA%E4%BA%8E%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%92%8C%E7%BB%93%E6%9E%84%E5%8C%96%E5%8D%B7%E7%A7%AF%E8%A7%A3%E7%A0%81%E5%99%A8%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.sherlocknlp.com/《基于主题模板和结构化卷积解码器生成摘要》阅读笔记/</id>
    <published>2019-09-15T04:55:35.908Z</published>
    <updated>2019-09-15T13:24:27.839Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>来源：ACL 2019</p><p>原文链接：<a href="https://www.aclweb.org/anthology/P19-1504" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P19-1504</a></p><p>代码链接：<a href="https://github.com/lauhaide/WikiCatSum" target="_blank" rel="noopener">https://github.com/lauhaide/WikiCatSum</a></p></blockquote><p><img src="http://image.sherlocknlp.com/image/20190914/m2FdYXMbjJep.png" alt="mark"></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文基于假设——“将内容结构考虑在内的解码器会使摘要生成的结果更好，同时也会减少通用回复的问题”， 进行了以下研究。虽然文中多次提到多文档摘要，但并不是处理真正意义上的多文档摘要问题。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>本文模型仍然遵循传统的编码器-解码器架构，将输入文本编码成隐向量后从中解码出最终的摘要文本。模型的总体架构如下：</p><p><img src="http://image.sherlocknlp.com/image/20190914/8lYE59PakSeE.png" alt="mark"></p><h3 id="CNN-Encoder"><a href="#CNN-Encoder" class="headerlink" title="CNN Encoder"></a>CNN Encoder</h3><p>该模型在使用CNN [Gehring et al., 2017] 将输入文本编码，(作者说这里使用CNN来进行编码的原因是1）有利于并行训练；2）在生成式摘要任务上表现优秀。但后面解码时用的是LSTM，因此并行的效果有待考证)</p><p><img src="http://image.sherlocknlp.com/image/20190914/MzYKxEW3Ydmn.png" alt="mark"></p><h3 id="Hierarchical-Convolutional-Decoder"><a href="#Hierarchical-Convolutional-Decoder" class="headerlink" title="Hierarchical Convolutional Decoder"></a>Hierarchical Convolutional Decoder</h3><p>预测输出$y_{ti}$是通过卷积网络最顶层的输出$P\left(y_{t i} | y_{t\{1 : i-1\}}\right)=\operatorname{softmax}\left(W_{y}\left(\mathbf{o}_{t i}^{L}+\mathbf{c}_{t i}^{L}\right)\right)$。决定的该模型通过优化负对数似然$\mathcal{L}_{N L L}$来进行训练</p><p><img src="http://image.sherlocknlp.com/image/20190914/SSc32OzKIrEy.png" alt="mark"></p><h4 id="Document-level-Decoder"><a href="#Document-level-Decoder" class="headerlink" title="Document-level Decoder"></a>Document-level Decoder</h4><p>在该层会解码出句子表示序列$\left(\mathbf{s}_{1}, \cdots, \mathbf{s}_{|\mathcal{S}|}\right)$。(但是这里并不清楚$s_t$解码停止条件)</p><p>$\mathbf{h}_{t}=\mathrm{LSTM}\left(\mathbf{h}_{t-1}, \mathbf{s}_{t-1}\right)$</p><p>$\mathbf{s}_{t}=\tanh \left(\mathbf{W}_{s}\left[\mathbf{h}_{t} ; \mathbf{c}_{t}^{s}\right]\right)$</p><p>这里使用了soft attention [Luong et al., 2015] 的机制，详细原理可以参考<a href="[http://www.sherlocknlp.com/Attention%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0%EF%BC%88%E5%A4%9A%E7%AF%87%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%EF%BC%89/](http://www.sherlocknlp.com/Attention模型方法综述（多篇经典论文解读）/">这篇博客</a>)。</p><p>$\alpha_{t j}^{s}=\frac{\exp \left(\mathbf{h}_{t} \cdot \mathbf{z}_{j}\right)}{\sum_{j^{\prime}} \exp \left(\mathbf{h}_{t} \cdot \mathbf{z}_{j^{\prime}}\right)}$</p><p>$\mathbf{c}_{t}^{s}=\sum_{j=1}^{|\mathcal{X}|} \alpha_{t j}^{s} \mathbf{z}_{j}$</p><h4 id="Sentence-level-Decoder"><a href="#Sentence-level-Decoder" class="headerlink" title="Sentence-level Decoder"></a>Sentence-level Decoder</h4><p>在该部分，作者定义了target摘要句的词表示由 a）词嵌入；b）句内位置向量；c）句子位置向量，三部分组成。</p><p>$\mathbf{g}_{t i}=\operatorname{emb}\left(y_{t i}\right)+\mathbf{e}_{i}+\mathbf{e}_{t}$</p><p>每个摘要句子$s_{t}=\left(y_{t 1}, \dots, y_{t\left|s_{t}\right|}\right)$都是由sentence-level decoder生成的。</p><script type="math/tex; mode=display">\left\{\mathbf{o}_{t 1}^{l}, \cdots, \mathbf{o}_{t n}^{l}\right\}=\operatorname{conv}\left(\left\{\mathbf{o}_{t 1}^{\prime l-1}, \cdots, \mathbf{o}_{t n}^{\prime l-1}\right)\right.</script><script type="math/tex; mode=display">\mathbf{d}_{t i}^{l}=W_{d}^{l}\left(\mathbf{o}_{t i}^{l}+\mathbf{s}_{t}\right)+\mathbf{g}_{t i}</script><script type="math/tex; mode=display">a_{t i j}^{l}=\frac{\exp \left(\mathbf{d}_{t i}^{l} \cdot \mathbf{z}_{j}\right)}{\sum_{j^{\prime}} \exp \left(\mathbf{d}_{t i}^{l} \cdot \mathbf{z}_{j^{\prime}}\right)}</script><script type="math/tex; mode=display">\mathbf{c}_{t i}^{l}=\sum_{j=1}^{|\mathcal{X}|} a_{t i j}^{l}\left(\mathbf{z}_{j}+\mathbf{e}_{j}\right)</script><script type="math/tex; mode=display">\mathbf{o}_{t i}^{\prime l}=\mathbf{o}_{t i}^{l}+\mathbf{s}_{t}+\mathbf{c}_{t i}^{l}</script><h3 id="Topic-Guidance"><a href="#Topic-Guidance" class="headerlink" title="Topic Guidance"></a>Topic Guidance</h3><p>在主题判别模块，本文将每个句子看做一个文档，并利用LDA模型分析其中隐含的主题列表K，并为每一个句子打上最可能的主题标签。目的是是document-level decoder更能与主题相关。在这里，作者设计了一个辅助任务用document-level decoder得到的隐层表示来预测主题$k_{t}$，$P\left(k_{t} | s_{1 : t-1}\right)=\operatorname{softmax}\left(W_{k}\left(\mathbf{s}_{t}\right)\right)$ （这里不太清楚为什么不是$P(k_{t} | s_{t})$ ）。</p><p><img src="http://image.sherlocknlp.com/image/20190914/oIh3aVW4wevv.png" alt="mark"></p><p><strong>符号说明</strong></p><p>$\alpha_{t j}^{s}$：sentence-level decoder中attention的权重</p><p>$a_{t i j}^{l}$：document-level decoder中attention的权重</p><p>${c}_{t}^{s}$：document-level decoder中得到的attention表示</p><p>$e_i$：句内位置向量</p><p>$e_t$：句子位置向量</p><p>$\mathbf{o}_{t i}^{l}$：卷积神经网络第l层对第t句摘要的第i个词的解码输出</p><p>$s_t$：document-level decoder解码出第t句的隐层状态表示</p><p>$y_{t i}$：输出摘要中第t句的第i个词</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>本文在自己构造的数据集WIKICATSUM上进行实验，具体的数据集参数如下：</p><p><img src="http://image.sherlocknlp.com/image/20190914/K8TATIwLLkCa.png" alt="mark"></p><p>实验中将模型与谷歌2018年的工作进行对比。结果如下（TF-S2S是谷歌的工作）</p><p><img src="http://image.sherlocknlp.com/image/20190914/l7QbioMG5vGN.png" alt="mark"></p><p><img src="http://image.sherlocknlp.com/image/20190914/j5YhR5mq7AGB.png" alt="mark"></p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>（个人观点）本文最大贡献是分层解码部分，document-level decoder部分利用辅助任务捕捉到topic信息。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>Liu P J, Saleh M, Pot E, et al. Generating wikipedia by summarizing long sequences[J]. ICLR 2018.</p><p>Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. 2017. Convolutional Sequence to Sequence Learning ICML 2017</p><p>Thang Luong, Hieu Pham, and Christopher D. Manning. 2015. Effective approaches to attention-based neural machine translation. EMNLP 2015</p><p><a href="https://www.jiqizhixin.com/articles/2019-08-19-5" target="_blank" rel="noopener">ACL 2019 | 利用主题模板进行维基百科摘要生成</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;来源：ACL 2019&lt;/p&gt;
&lt;p&gt;原文链接：&lt;a href=&quot;https://www.aclweb.org/anthology/P19-1504&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.aclwe
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
  </entry>
  
  <entry>
    <title>天池——中文NLSQL挑战赛</title>
    <link href="http://www.sherlocknlp.com/%E4%B8%AD%E6%96%87NLSQL%E6%8C%91%E6%88%98%E8%B5%9B/"/>
    <id>http://www.sherlocknlp.com/中文NLSQL挑战赛/</id>
    <published>2019-08-19T02:26:12.119Z</published>
    <updated>2019-07-31T07:47:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://aliyuntianchiresult.cn-hangzhou.oss.aliyun-inc.com/public/files/forum/155954005537218641559540055098.jpeg" alt></p><p>比赛官网：<a href="https://tianchi.aliyun.com/competition/entrance/231716/information" target="_blank" rel="noopener">https://tianchi.aliyun.com/competition/entrance/231716/information</a></p><h2 id="竞赛题目"><a href="#竞赛题目" class="headerlink" title="竞赛题目"></a>竞赛题目</h2><p>首届中文NLSQL挑战赛，使用金融以及通用领域的表格作为数据源，提供在此基础上标注的自然语言与SQL语句的匹配对，目的是设计模型准确将自然语言转换成SQL（即Natural Language to SQL）</p><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>本次赛题提供4w条有标签数据作为训练集，1w条无标签数据作为测试集。其中，5千条测试集作为初赛测试集（对选手可见）；另外5千条作为复赛测试集（对选手不可见）。提供的数据集主要由3个文件组成，以训练集为例，包括train.json、train.tables.json及train.db。数据中每一个样本都对应着一个数据表，里面包含该表所有列名，以及相应的数据记录。原则上生成的SQL语句在对应的数据表上是可以执行的，并且都能返回有效的结果。</p><p>train.json</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     <span class="string">"table_id"</span>: <span class="string">"a1b2c3d4"</span>, <span class="meta"># 相应表格的id</span></span><br><span class="line">     <span class="string">"question"</span>: <span class="string">"世茂茂悦府新盘容积率大于1，请问它的套均面积是多少？"</span>, <span class="meta"># 自然语言问句</span></span><br><span class="line">    <span class="string">"sql"</span>:&#123; <span class="meta"># 真实SQL</span></span><br><span class="line">        <span class="string">"sel"</span>: [<span class="number">7</span>], <span class="meta"># SQL选择的列 </span></span><br><span class="line">        <span class="string">"agg"</span>: [<span class="number">0</span>], <span class="meta"># 选择的列相应的聚合函数, <span class="string">'0'</span>代表无</span></span><br><span class="line">        <span class="string">"cond_conn_op"</span>: <span class="number">0</span>, <span class="meta"># 条件之间的关系</span></span><br><span class="line">        <span class="string">"conds"</span>: [</span><br><span class="line">            [<span class="number">1</span>,<span class="number">2</span>,<span class="string">"世茂茂悦府"</span>], <span class="meta"># 条件列, 条件类型, 条件值，col_1 == <span class="string">"世茂茂悦府"</span></span></span><br><span class="line">            [<span class="number">6</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，SQL的表达字典说明如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">op_sql_dict</span> = &#123;<span class="number">0</span>:<span class="string">"&gt;"</span>, <span class="number">1</span>:<span class="string">"&lt;"</span>, <span class="number">2</span>:<span class="string">"=="</span>, <span class="number">3</span>:<span class="string">"!="</span>&#125;</span><br><span class="line"><span class="attr">agg_sql_dict</span> = &#123;<span class="number">0</span>:<span class="string">""</span>, <span class="number">1</span>:<span class="string">"AVG"</span>, <span class="number">2</span>:<span class="string">"MAX"</span>, <span class="number">3</span>:<span class="string">"MIN"</span>, <span class="number">4</span>:<span class="string">"COUNT"</span>, <span class="number">5</span>:<span class="string">"SUM"</span>&#125;</span><br><span class="line"><span class="attr">conn_sql_dict</span> = &#123;<span class="number">0</span>:<span class="string">""</span>, <span class="number">1</span>:<span class="string">"and"</span>, <span class="number">2</span>:<span class="string">"or"</span>&#125;</span><br></pre></td></tr></table></figure><p>主办方已经将SQL语句做了十分清晰的格式化，比如<code>sel</code>这个字段，其实就是一个多标签分类模型，只不过类别可能会随时变化。<code>agg</code>则跟<code>sel</code>是一一对应的，并且类别是固定的，<code>cond_conn_op</code>则是一个单标签分类问题。</p><p>train.tables.json </p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"id"</span>:<span class="string">"a1b2c3d4"</span>, <span class="meta"># 表格id</span></span><br><span class="line">    <span class="string">"name"</span>:<span class="string">"Table_a1b2c3d4"</span>, <span class="meta"># 表格名称</span></span><br><span class="line">    <span class="string">"title"</span>:<span class="string">"表1：2019年新开工预测 "</span>, <span class="meta"># 表格标题</span></span><br><span class="line">    <span class="string">"header"</span>:[ <span class="meta"># 表格所包含的列名</span></span><br><span class="line">        <span class="string">"300城市土地出让"</span>,</span><br><span class="line">        <span class="string">"规划建筑面积(万㎡)"</span>,</span><br><span class="line">        ……</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"types"</span>:[ <span class="meta"># 表格列所相应的类型</span></span><br><span class="line">        <span class="string">"text"</span>,</span><br><span class="line">        <span class="string">"real"</span>,</span><br><span class="line">        ……</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"rows"</span>:[ <span class="meta"># 表格每一行所存储的值</span></span><br><span class="line">        [<span class="meta"></span></span><br><span class="line"><span class="meta">            <span class="meta-string">"2009年7月-2010年6月"</span>,</span></span><br><span class="line"><span class="meta">            168212.4,</span></span><br><span class="line"><span class="meta">            ……</span></span><br><span class="line"><span class="meta">        </span>]</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>tables.db为sqlite格式的数据库形式的表格文件。各个表的表名为tables.json中相应表格的name字段。为避免部分列名中的特殊符号导致无法存入数据库文件，表格中的列名为经过归一化的字段，col_1, col_2, …, col_n。</p><h2 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h2><h3 id="SQLNet"><a href="#SQLNet" class="headerlink" title="SQLNet"></a>SQLNet</h3><p><img src="http://image.sherlocknlp.com/image/20190731/m212El1C4qEJ.png?imageslim" alt="mark"></p><p>该模型将生成整个SQL的任务分解为多个子任务，包括select-number，选择哪一列select-column，使用什么聚合函数select-aggregation，有几个条件condition-number，筛选条件针对哪几列condition-column等。</p><p>paper：<a href="https://arxiv.org/pdf/1711.04436.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.04436.pdf</a></p><p>code：<a href="https://github.com/xiaojunxu/SQLNet" target="_blank" rel="noopener">https://github.com/xiaojunxu/SQLNet</a></p><p>该模型使用sketch-based方法，来解决“order-matters”的问题。根据数据集中的数据特征以及编写SQL时的先后顺序，各个子任务之间存在如下图所示的依赖关系。这样的依赖关系可以一定程度上利用已预测好的任务来帮助下游任务更好地预测。</p><p><img src="http://image.sherlocknlp.com/image/20190626/qROywmML3cup.png" alt="mark"></p><p>预处理：schema linking</p><h4 id="sequence-to-set"><a href="#sequence-to-set" class="headerlink" title="sequence to set"></a>sequence to set</h4><p>由于出现在WHERE子句中的列名构成了所有列名集合的子集，因此得到where-column的预测概率如下：</p><script type="math/tex; mode=display">P_{\text { wherecol }}(\operatorname{col} | Q)=\sigma\left(u_{c}^{T} E_{c o l}+u_{q}^{T} E_{Q}\right)</script><p>其中$\sigma$是sigmoid激活函数，$E_{c o l}$和$E_{Q}$分别是列名和Query的embedding。</p><h4 id="column-attention"><a href="#column-attention" class="headerlink" title="column attention"></a>column attention</h4><h4 id="OP-slot"><a href="#OP-slot" class="headerlink" title="OP slot"></a>OP slot</h4><h4 id="VALUE-slot"><a href="#VALUE-slot" class="headerlink" title="VALUE slot."></a>VALUE slot.</h4><p>感觉<strong>”木桶效应“</strong>的短板就在这里了，此处解码器使用的是<strong>pointer network</strong>+<strong>column attention</strong>。</p><script type="math/tex; mode=display">{P_{\mathrm{val}}(i | Q, c o l, h)=\operatorname{softmax}(a(h))}</script><script type="math/tex; mode=display">\\ {a(h)_{i}=\left(u^{\mathrm{val}}\right)^{T} \tanh \left(U_{1}^{\mathrm{val}} H_{Q}^{i}+U_{2}^{\mathrm{val}} E_{c o l}+U_{3}^{\mathrm{val}} h\right) \quad \forall i \in\{1, \ldots, L\}}</script><p>$P_{\mathrm{val}}(i | Q, c o l, h)$代表着下一个token生成的概率。SQLNet简单地选择最有可能的token生成，直到生成<end>终止符为止。</end></p><h3 id="SQLova"><a href="#SQLova" class="headerlink" title="SQLova"></a>SQLova</h3><p>SQLova 是韩国 Naver 提出的一种模型，全名为 Search &amp; QLova，是作者们所在部门的名称。此方案是于 SQLNet 的基础上，在模型结构方面做了一些改进而得到的，并没有提出一些创新性的解决方案。</p><p>paper：<a href="https://arxiv.org/abs/1902.01069" target="_blank" rel="noopener">https://arxiv.org/abs/1902.01069</a></p><p>code：<a href="https://github.com/naver/sqlova" target="_blank" rel="noopener">https://github.com/naver/sqlova</a></p><p><img src="http://image.sherlocknlp.com/image/20190731/VsczS0D88yc6.png?imageslim" alt="mark"></p><p>SQLova 使用了 BERT 来作为模型的输入表达层，代替了词向量。为了让自然语言问句与表结构更好地结合，模型将自然语言问句与列名一并作为输入进行编码。同时，模型在拼接输入时采用了不同的 Segmentation Embedding 来让 BERT 可以区分问题和列名。</p><h3 id="X-SQL"><a href="#X-SQL" class="headerlink" title="X-SQL"></a>X-SQL</h3><p><img src="http://image.sherlocknlp.com/image/20190709/qLWWqpMLx4Q3.png" alt="mark"></p><p>X-SQL 是微软 Dynamics 365 提出一种方案。这个方案同样继承了解耦任务的思路，将预测 SQL 分解为 6 个子任务。但不同于 SQLova，X-SQL 引入了更多创新性的一些改进，主要包括以下几个方面。 </p><ul><li><p>首先，X-SQL 使用了 MT-DNN 来作为编码层，代替了 SQLova 中使用的 BERT，因为 MT-DNN 在很多其它自然语言处理的下游任务上取得了比 BERT 更好的效果。</p></li><li><p>其次，X-SQL 在 SQLova 中原有的 Question Segmentation 和 Column Segmentation 的基础上拓展为 Question、Categorical Column、Numerical Column 以及 Empty Column 这四种 Segmentation Embedding，分别用来作为<strong>自然语言问句</strong>、<strong>文本类型的列</strong>、<strong>数字类型的列</strong>以及<strong>空列</strong>的相应输入。通过引入更多的分类表达，可以让模型得以区分数字与文本类型的列，进而更好地生成 SQL。 </p></li><li><p>最后，在输出层与损失函数部分，Where-Column 的损失函数被定义为了 KL 散度。并且，借助之前提到的引入的特殊列 [EMPTY]，如果模型在预测 Where-Column 时，分数最高的列是 [EMPTY]，那么就无视 Where-Number 所得到的预测结果，判断 SQL 语句为没有条件。 </p></li></ul><p>通过这些输入与结构上的优化，X-SQL 可以在 WikiSQL 的测试集上取得 86.0% 的 Logic Form 准确率和 91.8% 的 Execution 准确率。 </p><h3 id="苏剑林老师基于BERT的baseline"><a href="#苏剑林老师基于BERT的baseline" class="headerlink" title="苏剑林老师基于BERT的baseline"></a>苏剑林老师基于BERT的baseline</h3><p><img src="http://image.sherlocknlp.com/image/20190630/mNz6LiUM0yhC.png" alt="mark"></p><p>代码：<a href="https://github.com/bojone/bert_in_keras/blob/master/nl2sql_baseline.py" target="_blank" rel="noopener">https://github.com/bojone/bert_in_keras/blob/master/nl2sql_baseline.py</a></p><h2 id="评价标准"><a href="#评价标准" class="headerlink" title="评价标准"></a>评价标准</h2><p>对于模型的评估，其主要有两个指标：Logic form Accuracy和Execution Accuracy，最后选手排名的依据是两项指标的平均值。</p><p><strong>Logic Form Accuracy</strong>: 预测完全正确的SQL语句。其中，列的顺序并不影响准确率的计算。<br><strong>Execution Accuracy</strong>: 预测的SQL的执行结果与真实SQL的执行结果一致。</p><p>计算公式如下：</p><script type="math/tex; mode=display">Score_{l f}=\left\{\begin{array}{ll}{1,} & {S Q L^{\prime}=S Q L} \\ {0,} & {S Q L^{\prime} \neq S Q L}\end{array}\right.</script><script type="math/tex; mode=display">A c c_{l f}=\frac{1}{N} \sum_{n=1}^{N} S c o r e_{l f}^{n}</script><script type="math/tex; mode=display">Score_{e x}=\left\{\begin{array}{ll}{1,} & {Y^{\prime}=Y} \\ {0,} & {Y^{\prime} \neq Y}\end{array}\right.</script><script type="math/tex; mode=display">A c c_{e x}=\frac{1}{N} \sum_{n=1}^{N} S c o r e_{e x}^{n}</script><p>最后线上的评估指标为<strong>（Logic Form Accuracy + Execution Accuracy）/ 2</strong></p><h2 id="其他相似任务"><a href="#其他相似任务" class="headerlink" title="其他相似任务"></a>其他相似任务</h2><p>WikiSQL数据集提供了8w多条有标签数据，足以满足目前的数据驱动型算法对数据量的需求。目前榜单上，效果最好的模型是SQLova和X-SQL，它们在测试集上分别可以达到89.6%和91.8%的执行准确率。</p><p><img src="http://image.sherlocknlp.com/image/20190626/YvKaWleyerov.png" alt="mark"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247497889&amp;idx=1&amp;sn=1abe1d11b147c76f21dc43e3a5cdaf41&amp;chksm=96ea2721a19dae37c3015f9e2ed981f69abf592aa82f03a0f9367ecee4f90f2a5ea707f24cd4&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;key=a9ac41334684e0a1938e8c86e8bfae37fcbb95953f6624213d75bd0eedfbd2685081d8aed77406586738cd1a287540efaa268f65e222d95a1e39ea05781ab3d4465d62c9514bf6b4d9b57ed8c6c42757&amp;ascene=1&amp;uin=MjQzNDM1OTMwMQ%3D%3D&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=cipBWFLJOgqM9Pb08AxN1Z6n0dxWoUUil6zopvkLamsGj2IaFDKkQ%2BW%2B%2FNu5X4HZ" target="_blank" rel="noopener">NL2SQL：弱监督学习与有监督学习完成进阶之路</a></p><p><a href="https://www.jiqizhixin.com/articles/2019-06-24-10" target="_blank" rel="noopener">让机器自动写SQL语言，首届中文NL2SQL挑战赛等你来战</a></p><p><a href="https://zhuanlan.zhihu.com/p/70408854" target="_blank" rel="noopener">SQLNet——知乎</a></p><p><a href="https://kexue.fm/archives/6771" target="_blank" rel="noopener">基于Bert的NL2SQL模型：一个简明的Baseline</a></p><p><a href="https://einstein.ai/research/blog/how-to-talk-to-your-database" target="_blank" rel="noopener">How to Talk to Your Database</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;http://aliyuntianchiresult.cn-hangzhou.oss.aliyun-inc.com/public/files/forum/155954005537218641559540055098.jpeg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;比
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
  </entry>
  
  <entry>
    <title>DeeCamp 2019：Day 1</title>
    <link href="http://www.sherlocknlp.com/DeeCamp-2019%EF%BC%9ADay-1/"/>
    <id>http://www.sherlocknlp.com/DeeCamp-2019：Day-1/</id>
    <published>2019-08-19T02:26:11.870Z</published>
    <updated>2019-07-28T11:52:52.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://image.sherlocknlp.com/image/20190720/7EoS9nhQcxYr.png" alt="mark"></p><p>7月20日，DeeCamp 2019正式开营。</p><p>创新工场董事长兼CEO李开复，上海交通大学特聘教授、博士生导师俞勇，香港科技大学计算机系和数学系，机器学习领域的世界级专家张潼，人工智能领域世界级专家、南京大学人工智能学院院长周志华四位重磅级导师亲临北京、上海、广州、南京四座城市，分别开讲第一课。</p><p>以下是今天四位老师分享的<strong>课题</strong>：</p><ul><li><p>AI应用阶段的全球人才挑战——李开复</p></li><li><p>AI 教育与教育AI：愿景、技术和挑战——俞勇</p></li><li><p>机器学习的一些前沿方向和进展——张潼</p></li><li><p>机器学习现阶段的挑战——周志华</p></li></ul><h2 id="机器学习的一些前沿方向"><a href="#机器学习的一些前沿方向" class="headerlink" title="机器学习的一些前沿方向"></a>机器学习的一些前沿方向</h2><p><img src="http://image.sherlocknlp.com/image/20190724/Heix8kKsznNv.png" alt="mark"></p><p><strong>前沿</strong></p><p>更深更复杂的模型提升效果——&gt;基于向量的表示获得广泛应用——&gt;自动化机器学习——&gt;基于模拟的强化学习</p><p>复杂场景、小数据学习、物理世界中具体任务</p><h3 id="复杂模型"><a href="#复杂模型" class="headerlink" title="复杂模型"></a>复杂模型</h3><p><strong>Why deep NN?</strong></p><p>More <strong>efficient</strong> representation of some complex functions. Over parameterized DNN can be efficient learned（high complexity matters：Adding layers is more effective than adding units）</p><ul><li><p>big training data</p></li><li><p>powerful computational facilities</p></li><li><p>training tricks（dropout、batch normalization、residual networks等）</p></li></ul><p><img src="http://image.sherlocknlp.com/image/20190724/54idXLCpRDhH.png" alt="mark"></p><p><strong>Deep model的关键</strong></p><ul><li><p>逐层处理 layer-by-layer processing</p></li><li><p>内置特征变换</p></li><li><p>模型复杂度足够</p></li></ul><p>现实世界并非所有规律性质都是可微的，或者通过可微构件建模最优。在图像、视频、语音之外的很多任务上，深度神经网络并非最佳选择不少时候甚至表现不佳。例如，在很多kaggle competition任务上，随机森林或者是XGBoost更好</p><p><strong>决策树？Boosting?</strong></p><p><img src="http://image.sherlocknlp.com/image/20190724/P7K8MJKP6PGb.png" alt="mark"></p><p>决策树和Boosting虽然可以逐层处理，但是复杂度不够并且没有特征变换。</p><p><strong>an Alternative to Deep Neural Networks: <a href="https://www.ijcai.org/proceedings/2017/0497.pdf" target="_blank" rel="noopener">dcforest</a></strong></p><h3 id="表示学习"><a href="#表示学习" class="headerlink" title="表示学习"></a>表示学习</h3><p><strong>目标：</strong>represent data by a vector, also called embedding. The vector can be used for different machine learning tasks.</p><p><strong>什么是表示学习？</strong> </p><p>通俗易懂的解释就是用数字（向量、矩阵…）来表达现实世界中的物体（object），而且这种表达方式有利于后续的分类或者其他决策问题。</p><p>对于NLP方向的表示学习可以参考下面这篇博客——<a href="[http://www.sherlocknlp.com/NLP%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/](http://www.sherlocknlp.com/NLP文本表示预训练技术/">《NLP文本表示预训练技术》</a>)</p><h3 id="自动机器学习"><a href="#自动机器学习" class="headerlink" title="自动机器学习"></a>自动机器学习</h3><p><strong>Components of an NAS System</strong></p><ul><li>Search  Space Design</li><li>Search Algorithm Design<ul><li>Reinforcement Learning</li><li>Evolutionary Algorithms</li><li>Continuous relaxation</li></ul></li></ul><p><img src="http://image.sherlocknlp.com/image/20190724/tfgOhFovJ1jG.png" alt="mark"></p><h2 id="机器学习现阶段的挑战"><a href="#机器学习现阶段的挑战" class="headerlink" title="机器学习现阶段的挑战"></a>机器学习现阶段的挑战</h2><p><strong>一些问题</strong></p><ul><li><p>鲁棒性不强</p></li><li><p>场景变动带来的自适应性不强</p></li><li><p>任务可扩展性不强</p></li><li><p>对世界知识表示得不好</p></li></ul><p><strong>能否基于不可微的构件进行深度学习？</strong></p><p><strong>unkown unkowns 我不知道我不知道这件事 robust AI</strong></p><p><strong>弱监督学习</strong></p><p><img src="http://image.sherlocknlp.com/image/20190724/M9AQtkdjEBth.png" alt="mark"></p><p><strong>任务环境静态</strong></p><ul><li><p>数据分布恒定</p></li><li><p>样本类别恒定</p></li><li><p>属性恒定</p></li><li><p>优化目标恒定</p></li></ul><p><strong>How to handle emerging new class in stream？</strong> </p><p>增量学习（Incremental learning）</p><p><strong>机器学习+逻辑系统 inductive</strong></p><p>附一张开营照，以证清白</p><p><img src="http://image.sherlocknlp.com/image/20190725/RmTD3nSJmClk.png?imageslim" alt="mark"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzIyOTkzNDU5OQ==&amp;mid=2247489765&amp;idx=1&amp;sn=1aab77fa7f48bf05bfbc846ccc927efe&amp;chksm=e8ba4b8ddfcdc29b81c2c364ee33f222a730b03e7d2b6b4c9005bf50b9255f1cdfd457e3411a&amp;scene=7&amp;key=b062814be2bd9814fdf5571ab325e98e83822e5cdf1bc732c3a689ffdd740a1d86fd32bc5ffc590dcd7f0ab3e7eb109431a5ff24e1b89623b2fdace372a1f295efa0bc8c55ec506d09c9ddbbd04a3ed5&amp;ascene=0&amp;uin=MjQzNDM1OTMwMQ%3D%3D&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=jXEj48WgKrULR9t9jP%2FSBRo6H4Wx4iA35CCLKNR6mFOB0XGZMjioqXUB%2BYpnc5nX" target="_blank" rel="noopener">深度学习的未来：神经网络架构搜索(NAS)</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247491248&amp;idx=1&amp;sn=d2946d8a37f7c6567b1a767a497006fb&amp;chksm=96e9c130a19e48267f72ad32c527ec4a1697741e409d865d9233c5d7035a1f66a59b5e40792d&amp;scene=7&amp;key=7a62ff320f98b892614d63e6563c9c38463fd196b10ebe4942f81be1bff940b2e63afd5c1622f2bb945e73a6e74430a0529d9660250d30220ebc618ed3430271eda2c4395e1fddfbd570be996abec3e1&amp;ascene=0&amp;uin=MjQzNDM1OTMwMQ%3D%3D&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=PFQ44Yicoh22dv%2BKArSx8Qdp5VlOVPdBSW6wYFwOkzgTZTbx46INCO6E12yXmLQM" target="_blank" rel="noopener">神经网络架构搜索（NAS）综述 | 附AutoML资料推荐</a></p><p><a href="https://www.microsoft.com/en-us/research/video/advanced-machine-learning-day-3-neural-architecture-search/" target="_blank" rel="noopener">Advanced Machine Learning Day 3: Neural Architecture Search</a></p><p>Liang S , Srikant R . Why Deep Neural Networks for Function Approximation? ICLR-17</p><p>Mhaskar H, Liao Q, Poggio T. When and why are deep networks better than shallow ones?[C]//Thirty-First AAAI Conference on Artificial Intelligence. 2017.</p><p>Perekrestenko D, Grohs P, Elbrächter D, et al. The universal approximation power of finite-width deep ReLU networks[J]. arXiv preprint arXiv:1806.01528, 2018.</p><p>Du S S, Zhai X, Poczos B, et al. Gradient descent provably optimizes over-parameterized neural networks[J]. arXiv preprint arXiv:1810.02054, 2018.</p><p>Mei S, Montanari A, Nguyen P M. A mean field view of the landscape of two-layer neural networks[J]. Proceedings of the National Academy of Sciences, 2018, 115(33): E7665-E7671.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;http://image.sherlocknlp.com/image/20190720/7EoS9nhQcxYr.png&quot; alt=&quot;mark&quot;&gt;&lt;/p&gt;
&lt;p&gt;7月20日，DeeCamp 2019正式开营。&lt;/p&gt;
&lt;p&gt;创新工场董事长兼CEO李开复，
      
    
    </summary>
    
      <category term="note" scheme="http://www.sherlocknlp.com/categories/note/"/>
    
    
  </entry>
  
  <entry>
    <title>《Evolving Dialogue Strategy via Compound Assessment》阅读笔记</title>
    <link href="http://www.sherlocknlp.com/%E3%80%8AEvolving-Dialogue-Strategy-via-Compound-Assessment%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.sherlocknlp.com/《Evolving-Dialogue-Strategy-via-Compound-Assessment》阅读笔记/</id>
    <published>2019-07-22T10:11:50.759Z</published>
    <updated>2019-07-22T10:11:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>论文题目：Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment</p><p>论文链接：<a href="https://arxiv.org/pdf/1906.00549.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.00549.pdf</a></p><p>ACL 2019</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文认为在人类对话中，最终<strong>目标之一</strong>是信息可以通过互动有效地交换。 特别是，我们认为成功的多轮对话是由对话中两个参与者的共同经验决定的，即两个参与者都需要了解他们的对应部分并有效地表达自己。为此，我们提出让双方更多了解彼此的目标。为此目的，引入了一个新的生成 - 评估框架，用于多轮对话。</p><p><strong>本文的主要贡献</strong></p><ul><li>提出了一个新颖的生成-评估框架，这样有助于产生信息和连贯的对话。</li><li>为了评估对话策略的有效性，本文专门针对了信息量和连贯性设计了两个指标，这些指标进一步整合为复合奖励。为了最大化这种奖励，通过强化学习的方法加强知识选择策略。</li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p><img src="http://image.sherlocknlp.com/image/20190717/hbpkXEf1HuSH.png" alt="mark"></p><p>本文的生成-评估框架如上图所示，根据知识选择策略，两个对话代理根据相应的背景交替介绍自己。通过<strong>信息丰富性</strong>和<strong>相关性</strong>两个方面协同评估对话策略。</p><h3 id="Dialogue-Generation"><a href="#Dialogue-Generation" class="headerlink" title="Dialogue Generation"></a>Dialogue Generation</h3><p>以对话历史和背景知识作为输入，对话策略选择一条适当的知识来产生信息丰富且流畅的响应。背景$\mathcal{Z}=\left\{z_{1}, z_{2}, \cdots, z_{M}\right\}$包含一组知识的集合，在这里知识以一句话描述的形式表现，例如<code>I like to ski</code>。Utterance $u_{t-1}$是另一个参与者的最后一句响应，context $c_t=concat(u_{1}, u_{2}, \cdots, u_{t-1})$为当前对话历史信息。</p><p><img src="http://image.sherlocknlp.com/image/20190718/vg1tsDmX3qg1.png" alt="mark"></p><p>在对话中，输入的对话上下文历史信息$c_t$分为两部分：$u_{t-1}$和$c_{t-1}$，分别用独立的两个编码器进行编码。为了回复的连贯性，在t回合使用的知识应该在语义上与伙伴的最后一个话语$u_{t-1}$相关；为了避免重复，第t回合使用的知识应与之前对话历史$c_{t-1}$不同。</p><p>得到对话和知识信息的表示 knowledge——$z_{i}^{G}$，utterance——$u_{t-1}^{G}$，context——$c_{t-1}^{G}$，（$\mathcal{Z}^{G}=\left\{z_{1}^{G}, z_{2}^{G}, \cdots, z_{M}^{G}\right\}$）。知识的先验分布$p\left(\mathcal{Z} | c_{t}\right)$可以通过MLP attention来进行预测</p><script type="math/tex; mode=display">{p\left(\mathcal{Z} | c_{t}\right)=p\left(\mathcal{Z} | u_{t-1}\right) * 0.5+p\left(\mathcal{Z} | c_{t-1}\right) * 0.5}</script><script type="math/tex; mode=display">{p\left(z_{i} | u_{t-1}\right)=\operatorname{softmax}\left(\operatorname{MLP}-\operatorname{ATT}\left(u_{t-1}^{G}, z_{i}^{G}\right)\right)}</script><script type="math/tex; mode=display">{p\left(z_{i} | c_{t-1}\right)=\operatorname{softmax}\left(\operatorname{MLP}-\mathrm{ATT}\left(c_{t-1}^{G}, z_{i}^{G}\right)\right)}</script><p><strong>MLP-ATT</strong>的计算公式如下：</p><script type="math/tex; mode=display">\operatorname{MLP}-\operatorname{ATT}(x, y)=V_{1}^{T} \tanh \left(x W_{1}+y W_{2}\right)</script><p>注：$W_{1}, W_{2} \in \mathbb{R}^{d \times d}$，$V_{1} \in \mathbb{R}^{d}$，$p\left(\mathcal{Z} | c_{t}\right)$是知识选择的概率分布，$\sum_{i=1}^{M} p\left(z_{i} | c_{t}\right)=1$。根据概率分布$p\left(\mathcal{Z} | c_{t}\right)$来选择所需的知识$z_i$，并将其送入解码器生成回复的概率$p\left(u_{t} | z_{i}, u_{t-1}\right)$。</p><p>显然，对于信息丰富和连贯的对话最关键的部分是<strong>知识选择</strong>。然而，高精度的解码$p\left(u_{t} | z_{i}, u_{t-1}\right)$也同样重要。这部分通过已有的标准回复进行有监督的预训练实现，训练数据的格式为$\left\{u_{t-1}, z_{i}, u_{t}\right\}$。预训练的<strong>主要步骤</strong>如下：</p><p>1）将<strong>知识</strong>和<strong>utterance</strong>编码为$z_{i}^{G}$和$u_{t-1}^{G}$</p><p>2）基于<strong>标准知识</strong>和最后一个的utterance（ $u_{t-1}$ ）生成回复$u_t$</p><p>3）通过监督学习优化编码器和解码器的参数</p><h3 id="Strategy-Evaluation"><a href="#Strategy-Evaluation" class="headerlink" title="Strategy Evaluation"></a>Strategy Evaluation</h3><p>本文中的的对话是由两个对话代理生成（agent）。为了评估部署策略的有效性，首先收集生成的对话文本和对话代理的背景知识，然后精心设计指标评估对话的信息性（informativeness）和一致性（coherence）。</p><h4 id="informativeness"><a href="#informativeness" class="headerlink" title="informativeness"></a>informativeness</h4><p>信息是产生有意义对话的关键因素，但由于缺乏对有效信息利用的彻底控制，很容易产生重复的话语。本文设计了一种新颖的信息量度量的指标来衡量对话层面信息的有效利用。</p><p><img src="C:\Users\THINKPAD\AppData\Roaming\Typora\typora-user-images\1563780781345.png" alt="1563780781345"></p><h4 id="coherence"><a href="#coherence" class="headerlink" title="coherence"></a>coherence</h4><p><img src="http://image.sherlocknlp.com/image/20190718/JVw0FJe0MOLX.png" alt="mark"></p><script type="math/tex; mode=display">\alpha_t = sigmoid(v_u^T s_t)</script><script type="math/tex; mode=display">P_g(y_t=w_g) = softmax(W_g^o s_t)</script><script type="math/tex; mode=display">P_e(y_t=w_e) = softmax(W_e^o s_t)</script><script type="math/tex; mode=display">y_t o_t =P(y_t) = \alpha_t P_e(y_t=w_e) + (1-\alpha_t) P_y(y_t=w_g)</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>- </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文题目：Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment&lt;/p&gt;
&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.org/pdf/1906.00549
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
      <category term="dialogue system" scheme="http://www.sherlocknlp.com/tags/dialogue-system/"/>
    
  </entry>
  
  <entry>
    <title>NLP文本表示预训练技术</title>
    <link href="http://www.sherlocknlp.com/NLP%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/"/>
    <id>http://www.sherlocknlp.com/NLP文本表示预训练技术/</id>
    <published>2019-07-21T10:04:02.925Z</published>
    <updated>2019-11-19T05:13:00.103Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NLP里程碑"><a href="#NLP里程碑" class="headerlink" title="NLP里程碑"></a>NLP里程碑</h1><div class="table-container"><table><thead><tr><th>时间</th><th>事件</th></tr></thead><tbody><tr><td>2001</td><td>Neural Language Model</td></tr><tr><td>2008</td><td>Multi-task learning</td></tr><tr><td>2013</td><td>Word Embedding / NN for NLP</td></tr><tr><td>2014</td><td>Sequence to Sequence</td></tr><tr><td>2015</td><td>Attention</td></tr><tr><td>2016</td><td>Memory Network</td></tr><tr><td>2018</td><td>Pretrained Language Model</td></tr></tbody></table></div><p>通常来说，NLP 中监督任务的基本套路都可以用三个积木来进行归纳：</p><ul><li><p>文本数据搜集和预处理</p></li><li><p>将文本进行编码和表征</p></li><li><p>设计模型解决具体任务</p></li></ul><h1 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h1><p>语言模型是对一段文本的概率进行估计即针对文本$X$，计算$P(X)$的概率，语言模型分为<code>统计语言模型</code>和<code>神经网络语言模型</code>。</p><h2 id="统计语言模型-n-gram模型"><a href="#统计语言模型-n-gram模型" class="headerlink" title="统计语言模型/n-gram模型"></a>统计语言模型/n-gram模型</h2><p>语言模型的本质是对一段文本(词序列)进行预测概率的分布，即如果文本用 $X$ 来表示，那么语言模型就是要求 <script type="math/tex">P(X_i)</script>的大小。通俗的来讲，最后得到的概率越大说明越合理，概率越小越不合理（不是人话）。按照大数定律中频率对于概率无限逼近的思想，通过计算这个文本在所有人类历史上产生过的所有文本集合中的频率 $P(X_i)$ ，公式如下：</p><script type="math/tex; mode=display">P(X_i)=\frac{c(X_i)}{\sum_{i=0}^{\infty} c(X_i)}</script><p>该公式的问题是全人类所有历史语料的这种统计显然无法实现。因此我们将文本拆成词，通过词之间的概率关系，求得整个文本的概率大小。假定句子长度为T，词用x表示，即：</p><script type="math/tex; mode=display">P(X) = P(x_0, x_1,...,x_T)=P(x_0)*P(x_1|x_0)*P(x_2|x_0,x_1)...P(x_T|x_0,x_1,...,x_{T-1})</script><p><img src="http://i.loli.net/2019/05/03/5ccc41f42ddd1.png" alt="lm.png"></p><p>但是上式仍旧复杂，我们一般会引入马尔科夫假设：假定一个句子中词只与它前面的 n 个词相关。特别地，当n=1时句子的计算概率如下：</p><script type="math/tex; mode=display">P(X) = P(x_0, x_1,...,x_T)=P(x_0)P(x_1|x_0)P(x_2|x_1)...P(x_T|x_{T-1})=P(x_0)\prod_{i=0}^{T-1}P(x_{i+1}|x_{i})</script><p><strong>什么是马尔科夫假设？</strong></p><p>马尔科夫假设是指，每个词出现的概率只跟它前面的少数几个词有关。比如，二阶马尔科夫假设只考虑前面两个词，响应的语言模型是三元模型（3-gram）。引入了马尔科夫假设的语言模型，也可以叫做马克科夫模型。</p><p>然而，<strong>基于统计的语言模型存在着很多问题。</strong></p><h2 id="神经网络语言模型（NNLM）"><a href="#神经网络语言模型（NNLM）" class="headerlink" title="神经网络语言模型（NNLM）"></a>神经网络语言模型（NNLM）</h2><p>2003年Bengio在他的经典论文<a href="http://10.3.200.202/cache/10/03/www.jmlr.org/9633c9131df0a22183c7a64855a5d166/bengio03a.pdf" target="_blank" rel="noopener">A Neural Probabilistic Language Model</a>中，首次将深度学习的思想融入语言模型中，并发现将训练得到的NNLM（Neural Net Language Model, 神经网络语言模型）的第一层参数当作词的分布式表征（每个词表示为稠密的实数向量）时，能很好地获取词语之间的相似度。NNLM模型的目标是构建语言模型，而词向量只是一个副产物：</p><blockquote><p>The object is to learn a good model $f(w_t, …, w_{t-n+1})=$</p></blockquote><p><img src="https://note.youdao.com/yws/api/personal/file/1EEA06B143E5443E8DD91BCEA112909C?method=download&amp;shareKey=8c0244d2aaefd0e6ce47ed63ba0d2f6e" alt="nnlm"></p><p>NNLM的主要贡献是将模型的第一次层特征映射矩阵当作词的分布式表示，从而可以将一个词表示为一个向量形式。这直接启发了<strong>word2vec</strong>的工作。</p><p><strong>NNLM的问题：</strong> NNLM虽然将N-Gram的阶数n提高到了5，相比原来的统计语言模型进步很大，但这个级别的长程依赖关系仍不够。而且NNLM只对词的左侧文本进行建模，所以得到的词向量并不是语境的充分表征。还有一个比较严重的问题就是NNLM的训练太慢。</p><h1 id="自然语言预训练技术"><a href="#自然语言预训练技术" class="headerlink" title="自然语言预训练技术"></a>自然语言预训练技术</h1><h2 id="文本表示"><a href="#文本表示" class="headerlink" title="文本表示"></a>文本表示</h2><p><strong>文本表示的方法</strong></p><ol><li>基于one-hot、tfidf、textrank等的bag-of-words;</li><li>主题模型：LSA、pLSA、LDA;</li><li>基于词向量的静态表示：word2vec、fastText、glove;</li><li>基于词向量的动态表示：elmo、gpt、bert</li></ol><p><strong>语言表征学习</strong></p><p>nlp在深度学习的基本单元是向量$\{x_1, x_2, …, x_n\}$，然后通过变换、整合得到新的<strong>向量h</strong>——<strong>表征（Representation）</strong>，再基于向量h得到对输出的判断y。</p><p><strong>分布式语义假设（Distributional Hypothesis）</strong></p><p>One shall know a word by the company it keeps.</p><h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>2013年，Tomas Mikolov连放几篇划时代的论文，其中最为重要的是两篇：<a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noopener">Efficient Estimation of Word Representations in Vector Space</a>（一文首次提出CBOW和Skip-gram模型）和<a href="https://arxiv.org/abs/1310.4546" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>(文中介绍了几种优化训练方法，包括Hierarchical Softmax)。<strong>鼎鼎有名的word2vec只是一个工具</strong>，背后的模型是CBOW和Skip-gram，并且使用了Hierarchical Softmax或Negative Sampling这些训练的优化方法。</p><h3 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h3><p>CBOW的全称是Continuous Bag-of-words，也就是连续的词袋模型，其目标函数如下：</p><p>首先，CBOW没有隐藏层，本质上只有两层结构。从这可以看出，CBOW有三个特点：第一，取消了NNLM中的隐藏层，直接将输入层和输出层相连；第二，在求语境context向量时，语境内的词序已经丢失；第三，因为最终的目标函数仍然是语言模型的目标函数，所以需要顺序遍历预料中的每一个词。</p><p>需要注意的是这里每个词对应到两个词向量，其中$e(w_t)$是词的输入向量，而$e^{‘}(w_t)$则是词的输出向量。</p><p><img src="https://note.youdao.com/yws/api/personal/file/AF7DF320CCB34CD2AABD89FA63D475DC?method=download&amp;shareKey=179e904a83f1b9edaf3e5f051e8bf138" alt="cbow"></p><h3 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h3><h3 id="word2vec工具的使用"><a href="#word2vec工具的使用" class="headerlink" title="word2vec工具的使用"></a>word2vec工具的使用</h3><p>源码地址：<a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">https://code.google.com/archive/p/word2vec/</a></p><p>下载源码后运行make进行编译：</p><p>训练命令：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./word2vec -train cutted_text.txt -output vectors.bin -cbow <span class="number">0</span> -size <span class="number">200</span> -window <span class="number">5</span> -negative <span class="number">0</span> -hs <span class="number">1</span> -sample <span class="number">1e-3</span> -threads <span class="number">12</span> -binary <span class="number">1</span></span><br></pre></td></tr></table></figure><p>聚类：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./word2vec -train cutted_text.txt -output classes.txt -cbow <span class="number">0</span> -size <span class="number">200</span> -window <span class="number">5</span> -negative <span class="number">0</span> -hs <span class="number">1</span> -sample <span class="number">1e-3</span> -threads <span class="number">12</span> -classes <span class="number">500</span></span><br></pre></td></tr></table></figure><p>按类别排序：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort classes<span class="selector-class">.txt</span> -k <span class="number">2</span> -n &gt; classes<span class="selector-class">.sorted</span><span class="selector-class">.txt</span></span><br></pre></td></tr></table></figure><h2 id="Glove"><a href="#Glove" class="headerlink" title="Glove"></a>Glove</h2><p>Glove是一种用于获取单词向量表征的无监督学习算法。</p><p>目前将预训练语言表征应用于下游任务存在两种策略：基于<strong>特征的策略</strong>和<strong>微调的策略（fine-tuning）</strong>。基于特征的策略（如ELMo）使用将预训练的表征作为额外特征。而微调策略（GPT），通过简单地微调预训练参数在下游任务中进行训练。</p><h2 id="CoVe"><a href="#CoVe" class="headerlink" title="CoVe"></a>CoVe</h2><p><img src="http://image.sherlocknlp.com/image/20191119/22dKKwackliJ.png" alt="mark"></p><h2 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h2><p>2018年的早些时候吧，AllenNLP的Matthew E. Peters 等人在论文Deep contextualized word representations中首次提出<strong>ELMo</strong>，它的全称是Embeddings from Language Models。与word2vec或GLoVe等传统词嵌入不同，ELMo中每个词对应的向量实际上是一个包含该词的整个个句子的函数。</p><p>ELMo</p><p><img src="http://image.sherlocknlp.com/image/20191119/cEI1lkByGdJ6.png" alt="mark"> </p><p><img src="http://image.sherlocknlp.com/image/20191119/iH1SsGAE6rLI.png" alt="mark"> </p><p>ELMo的使用过程分为以下三个步骤：</p><p><img src="http://image.sherlocknlp.com/image/20191119/7y1fjPMaVM3L.png" alt="mark"></p><ol><li>预训练，ELMo利用2层的biLSTM和无监督数据训练两个单向的语言模型，统称为biLM；</li><li>利用特定任务的数据精调第一步的biLM;</li><li>训练特定的任务模型，任务模型的输入是上面已训练的biLM的各层状态向量的组合向量。</li></ol><h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2><p><img src="http://image.sherlocknlp.com/image/20191119/34IbIc5VUhlx.png" alt="mark"></p><p><a href="https://transformer.huggingface.co/" target="_blank" rel="noopener">https://transformer.huggingface.co/</a></p><p><img src="http://image.sherlocknlp.com/image/20191119/PWGBXlBfOP0f.png" alt="mark"> </p><h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><p> <img src="http://image.sherlocknlp.com/image/20191119/P2oMP9qOh7g4.png" alt="mark"> </p><p>BERT是一种预训练语言表示的方法，这意味着我们在大型文本语料库（如维基百科）上训练通用的“语言理解”模型，然后将该模型用于我们关心的下游NLP任务（如问答）。 BERT优于以前的方法，因为它是第一个用于预训练NLP的无监督，深度双向系统。</p><p><img src="http://image.sherlocknlp.com/image/20191119/4Pl1eTTKNDDS.png" alt="mark"></p><p>BERT联合<code>遮蔽语言模型（masked language model, MLM）</code>和<code>下一句预测（next sentence prediction）</code>两个任务联合预训练文本的表征。</p><h3 id="任务1：Masked-LM"><a href="#任务1：Masked-LM" class="headerlink" title="任务1：Masked LM"></a>任务1：Masked LM</h3><p>为了训练深度双向表征，BERT模型采取了一个直接的方法，随机遮蔽输入token的某些部分，然后预测被遮住的token。该步骤在文献中通常被称为Cloze任务（Taylor, 1953）。在这种情况下，对应遮蔽的token的最终隐藏向量会输入到softmax函数中，并如标准的LM那样预测所有词汇的概率。在实验中，随机遮住每个序列15%的token。与去噪自编码器（Vincent et al., 2008）相反，我们仅预测遮蔽单词而非重建整个输入。</p><h3 id="任务2：下一句预测"><a href="#任务2：下一句预测" class="headerlink" title="任务2：下一句预测"></a>任务2：下一句预测</h3><p>很多重要的下游任务（如问答QA和自然语言推断NLI）基于对两个文本句子之间关系的理解。</p><p>BERT最主要的几个特征：</p><ul><li>利用了“真”双向的Transformer;</li><li>为了利用双向信息，改进了普通语言模型为完形填空式的Mask-LM；</li><li>利用Next Sentence Prediction任务学习句子级别的信息；</li><li>进一步完善和扩展了GPT中设计的通用框架；使得BERT能够支持包括：句子对分类任务、单句子分类任务、阅读理解任务和序列标注任务。</li></ul><h3 id="如何使用BERT"><a href="#如何使用BERT" class="headerlink" title="如何使用BERT"></a>如何使用BERT</h3><p>使用BERT有两个阶段：<strong>预训练（Pre-training）</strong>和<strong>微调（Fine-tuning）</strong>。</p><ul><li><p><strong>预训练</strong>费用相当昂贵（4到16个云TPU为4天）。大多数NLP研究人员不需要从头开始训练他们自己的模型。</p></li><li><p><strong>微调</strong>取决于下游的具体任务，不同的下游任务意味着不同的网络扩展结构。总的来说，对BERT的微调是一个轻量级任务，微调主要调整的是扩展网络而不是BERT本身。换句话说，我们完全可以固定住BERT的参数，把BERT输出的向量编码当做一个特征信息，用于各种下游任务。</p></li></ul><p><img src="http://image.sherlocknlp.com/image/20191119/lRE5hg7nTSB0.png" alt="mark"></p><p><a href="https://jalammar.github.io/illustrated-bert/" target="_blank" rel="noopener">https://jalammar.github.io/illustrated-bert/</a></p><p><strong>将学习转移到下游任务</strong></p><p><img src="http://image.sherlocknlp.com/image/20191119/hAS6mGaeNkPX.png" alt="mark"></p><p><strong>使用Pytorch版本BERT的使用方式</strong></p><p> <img src="http://image.sherlocknlp.com/image/20191119/pqmiGLPmea76.png" alt="mark"> </p><p>1）First prepare a <strong>tokenized input</strong> with BertTokenizer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertModel, BertForMaskedLM</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 加载词典 pre-trained model tokenizer (vocabulary)</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Tokenized input</span></span><br><span class="line">text = <span class="string">"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]"</span></span><br><span class="line">tokenized_text = tokenizer.tokenize(text)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Mask a token that we will try to predict back with `BertForMaskedLM`</span></span><br><span class="line">masked_index = <span class="number">8</span></span><br><span class="line">tokenized_text[masked_index] = <span class="string">'[MASK]'</span></span><br><span class="line"><span class="keyword">assert</span> tokenized_text == [<span class="string">'[CLS]'</span>, <span class="string">'who'</span>, <span class="string">'was'</span>, <span class="string">'jim'</span>, <span class="string">'henson'</span>, <span class="string">'?'</span>, <span class="string">'[SEP]'</span>, <span class="string">'jim'</span>, <span class="string">'[MASK]'</span>, <span class="string">'was'</span>, <span class="string">'a'</span>, <span class="string">'puppet'</span>, <span class="string">'##eer'</span>, <span class="string">'[SEP]'</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将 token 转为 vocabulary 索引</span></span><br><span class="line">indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)</span><br><span class="line"><span class="comment"># 定义句子 A、B 索引</span></span><br><span class="line">segments_ids = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将 inputs 转为 PyTorch tensors</span></span><br><span class="line">tokens_tensor = torch.tensor([indexed_tokens])</span><br><span class="line">segments_tensors = torch.tensor([segments_ids])</span><br></pre></td></tr></table></figure><p>2）use <strong>BertModel</strong> to get hidden states</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 加载模型 pre-trained model (weights)</span></span><br><span class="line">model = BertModel.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"> </span><br><span class="line"><span class="meta"># GPU &amp; put everything on cuda</span></span><br><span class="line">tokens_tensor = tokens_tensor.<span class="keyword">to</span>(<span class="string">'cuda'</span>)</span><br><span class="line">segments_tensors = segments_tensors.<span class="keyword">to</span>(<span class="string">'cuda'</span>)</span><br><span class="line">model.<span class="keyword">to</span>(<span class="string">'cuda'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="meta"># 得到每一层的 hidden states </span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    encoded_layers, _ = model(tokens_tensor, segments_tensors)</span><br><span class="line"><span class="meta"># 模型 bert-base-uncased 有12层，所以 hidden states 也有12层</span></span><br><span class="line">assert len(encoded_layers) == <span class="number">12</span></span><br></pre></td></tr></table></figure><p><strong>两行代码玩转Google句向量和词向量</strong></p><p><img src="https://pic1.zhimg.com/v2-f22e216a969ff93bec51fa05d610c35c_b.gif" alt="mark"></p><h2 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzUyOTU2MjE1OA==&amp;mid=2247484863&amp;idx=1&amp;sn=fcb7e5b810cc34ac0035bc88b797eeaf&amp;chksm=fa5e6afecd29e3e8caf0b6381b2694da27122b1fbc062f67f4ee32cb19fe12ac50dd81c7ecca&amp;token=1724747136&amp;lang=zh_CN&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">干货|全面理解N-Gram语言模型</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247493520&amp;idx=1&amp;sn=2b04c009ef75291ef3d19e8fe673aa36&amp;chksm=96ea3810a19db10621e7a661974c796e8adeffc31625a769f8db1d87ba803cd58a30d40ad7ce&amp;scene=0&amp;xtrack=1#rd" target="_blank" rel="noopener">深度长文：NLP的巨人肩膀（上）</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247493731&amp;idx=1&amp;sn=51206e4ca3983548436d889590ab5347&amp;chksm=96ea37e3a19dbef5b6db3143eb9df822915126d3d8f61fe73ddb9f8fa329d568ec79a662acb1&amp;scene=0&amp;xtrack=1#rd" target="_blank" rel="noopener">NLP 的巨人肩膀（下）：从 CoVe 到 BERT</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&amp;mid=2247489766&amp;idx=1&amp;sn=7b8f822bbbb341bd9c241243a270f994&amp;chksm=fbd27447cca5fd51bcc6763d88af7f86707bf2aeb3a6a8f06c6e592927b3a4ebac5715472dbe&amp;mpshare=1&amp;scene=1&amp;srcid=#rd" target="_blank" rel="noopener">从Word Embedding到Bert模型——自然语言处理预训练技术发展史</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652033813&amp;idx=3&amp;sn=ba5712022bca369e2fd8542fececaa57&amp;chksm=f121a7e4c6562ef24383c563bce4bb8b14dc38c03bfe38fff64e1136eb2f6dc4ef230e2d1c00&amp;mpshare=1&amp;scene=1&amp;srcid=12147MftTWLeas3WahcyLXwm#rd" target="_blank" rel="noopener">图解2018年领先的两大NLP模型：BERT和ELMo</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247492317&amp;idx=1&amp;sn=e823a75d9463257ed9ea7b3e4677c1ae&amp;chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&amp;mpshare=1&amp;scene=1&amp;srcid=11192aV1OaIEYwrNKjBzUr5T#rd" target="_blank" rel="noopener">自然语言处理中的语言模型预训练方法</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247486703&amp;idx=1&amp;sn=20a0dd81e1798c5372bb01a8aa0648d4&amp;chksm=eb50187cdc27916a92f43d47d11e6ba6b2440da439487ec3fe35304b857da02052294611b8c8&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;key=343f44ce21474cdb77a884be8d81b6d4326f5d56eaaf78f8f73b6ae747ccfae3bce5cb5c1647545b5ed3ea295b9c75eee2996a65a021e120660d58ebaa637c3e2613a699a60b6b80ebe442fa660109a8&amp;ascene=1&amp;uin=MjQzNDM1OTMwMQ%3D%3D&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=j12FLF58G%2F2UfcT0vHabYTcwGsc0j4pMPO%2BK%2BALorbZ4UfqtwE6afMC3snT0pAQZ" target="_blank" rel="noopener">NLP中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert</a></p><p><a href="https://blog.csdn.net/AZRRR/article/details/90705953" target="_blank" rel="noopener">BERT——CSDN</a></p><p><a href="https://mp.weixin.qq.com/s/HnGrSFCIsfoVLyE9RWM8eQ" target="_blank" rel="noopener">解密BERT</a></p><p><a href="https://blog.csdn.net/ccbrid/article/details/88732857" target="_blank" rel="noopener">Pytorch版本的BERT使用学习笔记</a></p><p><a href="https://zhuanlan.zhihu.com/p/50582974" target="_blank" rel="noopener">两行代码代码玩转Google BERT局向量词向量</a></p><p><a href="https://www.jiqizhixin.com/articles/2019-06-10-7" target="_blank" rel="noopener">Bert时代的创新：Bert在NLP各领域的应用进展</a></p><p><a href="https://www.jiqizhixin.com/articles/2019-06-27-18" target="_blank" rel="noopener">BERT时代与后时代的NLP（二）</a></p><p><a href="https://www.jiqizhixin.com/articles/2019-06-29-3" target="_blank" rel="noopener">拆解XLNet模型设计，回顾语言表征学习的思想演进</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NLP里程碑&quot;&gt;&lt;a href=&quot;#NLP里程碑&quot; class=&quot;headerlink&quot; title=&quot;NLP里程碑&quot;&gt;&lt;/a&gt;NLP里程碑&lt;/h1&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;时间
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
  </entry>
  
  <entry>
    <title>《使用执行指导文本到SQL解码生成》阅读笔记</title>
    <link href="http://www.sherlocknlp.com/%E3%80%8A%E4%BD%BF%E7%94%A8%E6%89%A7%E8%A1%8C%E6%8C%87%E5%AF%BC%E6%96%87%E6%9C%AC%E5%88%B0SQL%E8%A7%A3%E7%A0%81%E7%94%9F%E6%88%90%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.sherlocknlp.com/《使用执行指导文本到SQL解码生成》阅读笔记/</id>
    <published>2019-07-05T03:02:14.233Z</published>
    <updated>2019-07-05T03:05:27.282Z</updated>
    
    <content type="html"><![CDATA[<p>论文题目：<a href="https://arxiv.org/pdf/1807.03100.pdf" target="_blank" rel="noopener">Robust Text-to-SQL Generation with Execution-Guided Decoding</a></p><p>Execution-Guided Decoder在适当的时间步长评估部分生成的SQL语句，然后将那些无法完成的候选项排除（红色背景）。下图中，“opponent &gt; Haugar”会产生runtime error，而“opponent = UEFA”会产生一个空的查询。</p><p><img src="http://image.sherlocknlp.com/image/20190705/IsaBBwOoGJlB.png" alt="mark"></p><h2 id="Execution-Guided-Decoding"><a href="#Execution-Guided-Decoding" class="headerlink" title="Execution-Guided Decoding"></a>Execution-Guided Decoding</h2><p>这项工作的关键是，部分生成的SQL语句，可以为生成过程的其余部分提供指导。这项工作仅使用此信息来过滤掉无法完成正确查询的部分结果。</p><h3 id="执行错误-Execution-Errors"><a href="#执行错误-Execution-Errors" class="headerlink" title="执行错误(Execution Errors)"></a>执行错误(Execution Errors)</h3><p>SQL语句执行引擎可以识别以下问题：</p><ul><li><p><strong>Parsing errors：</strong>如果程序在语法上不正确，则会导致解析错误。这种错误在复杂查询中更常见（如GeoQuery和ATIS数据集中出现的那样）。与基于模板和基于插槽填充的模型相比，自回归模型更容易出现此类错误。</p></li><li><p><strong>Runtime erros：</strong>如果程序p的运算符类型与其操作数类型不匹配，则程序p会抛出运行时错误。这样的错误可能是由于聚合函数与其目标列之间的不匹配（例如，对具有字符串类型的列的总和）或条件运算符与其操作数之间的不匹配（例如，应用&gt;到一个float类型的列和一个string类型的常量）。</p></li><li><strong>Empty output：</strong>如果解码器生成的限制过于严格，那么程序有可能返回空结果</li></ul><h3 id="用执行结果指导解码（Using-Execution-Guidance-in-Decoding）"><a href="#用执行结果指导解码（Using-Execution-Guidance-in-Decoding）" class="headerlink" title="用执行结果指导解码（Using Execution Guidance in Decoding）"></a>用执行结果指导解码（Using Execution Guidance in Decoding）</h3><h4 id="EG-autoregressive-decoder"><a href="#EG-autoregressive-decoder" class="headerlink" title="EG + autoregressive decoder"></a>EG + autoregressive decoder</h4><p>它可以被视为应用于模型特定解码器单元DECODE的标准波束搜索的扩展。只要有可能（即，当当前时间步t的结果对应于可执行的部分程序时），该过程仅保留波束中对应于部分程序的前k个状态而没有执行错误或空输出。</p><p><img src="http://image.sherlocknlp.com/image/20190705/pyEWs3DMcnPI.png" alt="mark"></p><h4 id="EG-non-autoregressive-decoder"><a href="#EG-non-autoregressive-decoder" class="headerlink" title="EG + non autoregressive decoder"></a>EG + non autoregressive decoder</h4><p>在基于前馈网络的非自回归模型中，execution guidance可以用在解码后的过滤部分。（例如，舍弃产生execution errors的结果）</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="Pointer-SQL-EG"><a href="#Pointer-SQL-EG" class="headerlink" title="Pointer-SQL+EG"></a>Pointer-SQL+EG</h3><p><img src="http://image.sherlocknlp.com/image/20190705/606NCbfM18Ps.png" alt="mark"></p><h3 id="Coarse2Fine-EG"><a href="#Coarse2Fine-EG" class="headerlink" title="Coarse2Fine+EG"></a>Coarse2Fine+EG</h3><h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/71621323" target="_blank" rel="noopener">Execution-Guided Decoding——知乎</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文题目：&lt;a href=&quot;https://arxiv.org/pdf/1807.03100.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Robust Text-to-SQL Generation with Execution-Guided De
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
      <category term="NLG" scheme="http://www.sherlocknlp.com/categories/NLP/NLG/"/>
    
    
  </entry>
  
  <entry>
    <title>《情感对话生成》阅读笔记</title>
    <link href="http://www.sherlocknlp.com/%E3%80%8AEmotional%20Chatting%20Machine%20Emotional%20Conversation%20Generation%20with%20Internal%E3%80%8B/"/>
    <id>http://www.sherlocknlp.com/《Emotional Chatting Machine Emotional Conversation Generation with Internal》/</id>
    <published>2019-07-04T09:08:43.987Z</published>
    <updated>2019-07-04T11:06:14.647Z</updated>
    
    <content type="html"><![CDATA[<p>论文题目：Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</p><p>论文链接：<a href="https://arxiv.org/abs/1704.01074" target="_blank" rel="noopener">https://arxiv.org/abs/1704.01074</a></p><p>代码链接：<a href="https://github.com/tuxchow/ecm" target="_blank" rel="noopener">https://github.com/tuxchow/ecm</a></p><p>AAAI 2019</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>朱小燕、黄民烈老师团队发布的论文<a href="https://arxiv.org/abs/1704.01074" target="_blank" rel="noopener">「 Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory」</a>首次将情感因素引入了基于深度学习的生成式对话系统，提出了基于记忆网络的情感对话系统 <strong>Emotional Chatting Machine (ECM)</strong> ，在传统的 <strong>Sequence to Sequence</strong> 模型的基础上，ECM 使用了<strong>静态的情感向量嵌入表示</strong>，<strong>动态的情感状态记忆网络</strong>和<strong>情感词外部记忆的机制</strong>，使得 ECM 可以根据用户的输入以及指定情感分类输出相应情感的回复语句。</p><p>代码链接：<a href="https://github.com/tuxchow/ecm" target="_blank" rel="noopener">https://github.com/tuxchow/ecm</a></p><p><img src="https://note.youdao.com/yws/api/personal/file/9920911672A94FE9A3119AFD6253720B?method=download&amp;shareKey=e00d16fb600abf76761f4b92e2c54951" alt="ecm_table1"></p><p>本文用输入作为一种提示和期望的情感的反应，来产生一个回答，采用NLPCC数据集训练一个情感分类器，利用分类器对大规模的对话数据进行自动标注，划分了六类情感，怒、厌恶、快乐、喜欢、悲伤和其他，并用三元数据向量（posts，responses, emotion labels of responses)训练ECM模型。本文设计了一个ECM（Emotional Chatting Machine）框架的，基于记忆网络memory的具有情感生成机制的seq2seq编解码生成模型，模型利用GRU进行编解码。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p><img src="https://note.youdao.com/yws/api/personal/file/B280DF312FF744F0A06C31EC5A18947D?method=download&amp;shareKey=12ecdb0a8fa62c1909dfc87c851a6024" alt="model_structure"></p><p>模型的总体框架如上图所示，用户问题输入为“What a lovely day!”，通过 Encoder 将其编码为隐向量表示 h，然后通过注意力机制，结合 decoder 的状态向量 $s$ 在生成不同的词时，对问题的隐向量表示 h 的不同部分的信息选择性的加强，得到向量 $c$。指定情感类别为“Happiness”，经过索引得到情感类别嵌入向量，初始的情感状态记忆向量和相应的情感词表。decoder 接受经过注意力机制的问题向量 $c$，情感类别嵌入向量和初始的情感状态记忆向量作为输入，通过循环神经网络生成下个词的生成概率 o，之后再经过情感词表对情感词和非情感词的加权，得到最终词的生成概率，通过采样即可得到输出“Haha, so happy today!”。</p><h3 id="Encoder-Decoder-Attn框架"><a href="#Encoder-Decoder-Attn框架" class="headerlink" title="Encoder-Decoder-Attn框架"></a>Encoder-Decoder-Attn框架</h3><p><img src="https://note.youdao.com/yws/api/personal/file/F761136507CB4D248E3FFC6CE5F9F4BA?method=download&amp;shareKey=733e71450c39674c12a6ea371be49ac5" alt="attention"></p><p>编码器将输入序列$X=(x_1,x_2,…, x_n)$转化为隐层表示$h=(h_1,h_2,…, h_n)$:</p><script type="math/tex; mode=display">h_t = GRU(h_{t-1}, x_t)</script><p>解码器将上下文向量（context vector）$c_t$和上一个已解码的词向量$e(y_{t-1})$作为输入，使用另一个GRU来更新隐层状态：</p><script type="math/tex; mode=display">s_t = GRU(s_{t-1},[c_t;e(y_{t-1})])</script><p>$[c_t;e(y_{t-1})]$是两个向量的级联，在我们得到隐层向量$s_t$之后，解码器通过计算得到输出概率分布$o_t$生成新的词：</p><script type="math/tex; mode=display">y_t o_t = P(y_t|y_1,y_2,...,y_{t-1},c_t)= softmax(W_os_t)</script><h3 id="Emotional-Category-Embedding"><a href="#Emotional-Category-Embedding" class="headerlink" title="Emotional Category Embedding"></a>Emotional Category Embedding</h3><p>将情感的类别编码成低维度的向量，然后将情感向量$v_e$、向量$e(y_{t-1})$和上下文向量$c_t$合并到一起作为解码器的输入更新解码器的隐层状态$s_t$：</p><script type="math/tex; mode=display">s_{t}=GRU(s_{t-1}, [c_t;e(y_{t-1});v_e])</script><h3 id="Internal-Memory"><a href="#Internal-Memory" class="headerlink" title="Internal Memory"></a>Internal Memory</h3><p>Affect-lm模型论文中提到简单的情感向量嵌入的方式会影响句子语法的准确性。因此，本文设计了一个内部记忆模块在解码时捕捉情感的动态变化。</p><p><img src="https://note.youdao.com/yws/api/personal/file/DA8FDAA8F8B245B1B399018A62045AA9?method=download&amp;shareKey=9a873c20e10345844386f4a69605c2b0" alt="inter_memory"></p><p>本模块受到<a href="https://arxiv.org/abs/1705.04839" target="_blank" rel="noopener">Annotating and modeling empathy in spoken conversations</a>这篇论文启发，具体结构如上图。在每个时间步都会计算Read Gate $g_t^r$和Write Gate $g_t^r$：</p><script type="math/tex; mode=display">g_t^r = sigmoid(W_g^r[e(y_{t-1});s_{t-1};c_t])</script><script type="math/tex; mode=display">g_t^w = sigmoid(W_g^w[e(s_t])</script><p>$g_t^r$和$g_t^w$是用来对内部记忆模块进行读写操作的。这样每一个时间步,情感状态都会被$g_t^w$消除一部分，这与<a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener">Key-value memory networks</a>中<strong>DELETE</strong>操作十分相似。在最后一步时内部的情感信息会被减少至0，表示情感已经被全部表达。</p><script type="math/tex; mode=display">M_{r,t}^I = g_t^r \bigotimes M_{e,t}^I</script><script type="math/tex; mode=display">M_{r,t+1}^I = g_t^w \bigotimes M_{e,t}^I</script><script type="math/tex; mode=display">s_t = GRU(s_{t-1}, [c_t;e(y_{t-1};M_{e,t}^I)])</script><h3 id="External-Memory"><a href="#External-Memory" class="headerlink" title="External Memory"></a>External Memory</h3><p>针对不同的词汇所表达的感情，模型使用External Memory模块来建模显式的情感表达，给情感词汇和普通词汇赋予不同的生成概率。因此，模型可以选择从情感词汇和普通词汇中选择生成一个词。</p><p><img src="https://note.youdao.com/yws/api/personal/file/516AB12A9A254BBAA7D7358FB9974742?method=download&amp;shareKey=e900cb0b52de4cf12c712d6e6309dfe8" alt></p><script type="math/tex; mode=display">\alpha_t = sigmoid(v_u^T s_t)</script><script type="math/tex; mode=display">P_g(y_t=w_g) = softmax(W_g^o s_t)</script><script type="math/tex; mode=display">P_e(y_t=w_e) = softmax(W_e^o s_t)</script><script type="math/tex; mode=display">y_t o_t =P(y_t) = \alpha_t P_e(y_t=w_e) + (1-\alpha_t) P_y(y_t=w_g)</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">L(\theta) = - \sum_{t=1}^{m} p_t log(o_t) - \sum_{t=1}^{m} q_tlog(\alpha_t) + ||M_{e,m}^{I}||</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集：<a href="http://coai.cs.tsinghua.edu.cn/hml/challenge2017/" target="_blank" rel="noopener">NLPCC2017 Shared Task 4</a></p><p>情感分类数据集：NLPCC20132 and NLPCC20143（中文数据）<br>The taxonomy comes from <a href="http://tcci.ccf.org.cn/confere-nce/2014/dldoc/evatask1.pdf" target="_blank" rel="noopener">http://tcci.ccf.org.cn/confere-nce/2014/dldoc/evatask1.pdf</a></p><p>大连理工的情感词汇数据集：<a href="http://ir.dlut.edu.cn/news/detail/215" target="_blank" rel="noopener">http://ir.dlut.edu.cn/news/detail/215</a></p><h2 id="主要参考文献"><a href="#主要参考文献" class="headerlink" title="主要参考文献"></a>主要参考文献</h2><ul><li><p>[Ghosh et al. 2017] Ghosh, S.; Chollet, M.; Laksana, E.;<br>Morency, L.; and Scherer, S. 2017. Affect-lm: A neural<br>language model for customizable affective text generation.<br>In ACL, 634–642.</p></li><li><p>[Alam, Danieli, and Riccardi 2017] Alam, F.; Danieli, M.;<br>and Riccardi, G. 2017. Annotating and modeling empathy<br>in spoken conversations. CoRR abs/1705.04839.</p></li><li><p>[Miller et al. 2016] Miller, A. H.; Fisch, A.; Dodge, J.;<br>Karimi, A.; Bordes, A.; and Weston, J. 2016. Keyvalue<br>memory networks for directly reading documents. In<br>EMNLP, 1400–1409.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文题目：Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory&lt;/p&gt;
&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.o
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
      <category term="NLG" scheme="http://www.sherlocknlp.com/categories/NLP/NLG/"/>
    
    
  </entry>
  
  <entry>
    <title>基于 Hexo + Github Pages 搭建个人博客</title>
    <link href="http://www.sherlocknlp.com/%E5%9F%BA%E4%BA%8E%20Hexo%20+%20Github%20Pages%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://www.sherlocknlp.com/基于 Hexo + Github Pages 搭建个人博客/</id>
    <published>2019-07-04T01:00:47.528Z</published>
    <updated>2019-07-04T11:06:21.917Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备知识"><a href="#准备知识" class="headerlink" title="准备知识"></a>准备知识</h2><h3 id="什么是Github-Pages"><a href="#什么是Github-Pages" class="headerlink" title="什么是Github Pages?"></a>什么是Github Pages?</h3><h3 id="什么是Hexo？"><a href="#什么是Hexo？" class="headerlink" title="什么是Hexo？"></a>什么是Hexo？</h3><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a>是一个快速、简洁且高效的博客框架。Hexo使用<a href="http://daringfireball.net/projects/markdown/" target="_blank" rel="noopener">Markdown</a>解析文章，在几秒内，即可使用靓丽的主题生成静态网页。</p><h2 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li>Ubuntu 16.04</li><li><a href="https://git-scm.com/" target="_blank" rel="noopener">git</a></li><li><a href="https://nodejs.org/" target="_blank" rel="noopener">Node.js</a>：建议使用<a href="https://github.com/creationix/nvm" target="_blank" rel="noopener">nvm</a>进行安装</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget -qO- https:<span class="regexp">//</span>raw.githubusercontent.com<span class="regexp">/creationix/</span>nvm<span class="regexp">/v0.34.0/i</span>nstall.sh | bash</span><br><span class="line"></span><br><span class="line">nvm install stable</span><br></pre></td></tr></table></figure><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">官方安装文档</a></p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install hexo-<span class="keyword">cli</span> -g</span><br></pre></td></tr></table></figure><h3 id="在本地第一次部署"><a href="#在本地第一次部署" class="headerlink" title="在本地第一次部署"></a>在本地第一次部署</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> hexo init blog</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> blog</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hexo generate</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hexo server</span></span><br></pre></td></tr></table></figure><p>现在在浏览器中输入localhost:4000</p><ul><li>public: 执行hexo generate命令，输出的静态网页内容目录</li><li>scaffolds: layout模板文件目录</li><li>scripts： 扩展脚本目录，这里可以自定义一些javascript脚本</li><li>source： 文章源码目录，该目录下的markdown和html文件均会被hexo处理</li><li>drafts: 保存草稿文章</li><li>posts:</li><li>_config.yml: 网站的全局配置文件</li><li>package.json: hexo的版本信息</li></ul><h3 id="使用Next主题"><a href="#使用Next主题" class="headerlink" title="使用Next主题"></a>使用Next主题</h3><p>在Hexo中有两份主要的配置文件，其名称都是<code>_config.yml</code>。其中一份位于站点根目录下，主要包含Hexo本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。为了区分，我们将前者称为站点配置文件，后者称为主题配置文件。</p><p>下载<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">Next</a>主题<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/iissnan</span><span class="regexp">/hexo-theme-next themes/next</span></span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">修改主目录下的_config.yml配置文件</span></span><br></pre></td></tr></table></figure></p><p>theme: next<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在本地测试网站</span><br></pre></td></tr></table></figure></p><p>$ hexo clean<br>$ hexo generate<br>$ hexo server<br>```</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.shuang0420.com/2016/05/12/Github-Pages-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" target="_blank" rel="noopener">Github Pages+Hexo搭建个人博客</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;准备知识&quot;&gt;&lt;a href=&quot;#准备知识&quot; class=&quot;headerlink&quot; title=&quot;准备知识&quot;&gt;&lt;/a&gt;准备知识&lt;/h2&gt;&lt;h3 id=&quot;什么是Github-Pages&quot;&gt;&lt;a href=&quot;#什么是Github-Pages&quot; class=&quot;header
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://www.sherlocknlp.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>小冰架构学习</title>
    <link href="http://www.sherlocknlp.com/%E5%B0%8F%E5%86%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0/"/>
    <id>http://www.sherlocknlp.com/小冰架构学习/</id>
    <published>2019-07-04T01:00:46.883Z</published>
    <updated>2019-07-05T09:16:57.157Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2019/png/104214/1546396005189-1beef810-d825-4ea8-8597-3806892e92d4.png" alt></p><h2 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h2><p><strong>如何评价小冰Open Domain Social Long-term Dialogue System的性能？</strong></p><p>单次对话论述 Conversation-turns Per Session(CPS)作为评估社交聊天机器人成功的指标。CPS越大，社交聊天机器人的对话参与能力就越好。第六代小冰的CPS已经从第一代的5提升到23。</p><p><strong>IQ+EQ+Personality</strong></p><p>社交聊天机器人需要足够高的智商（IQ）来学习多种技能，才能紧跟用户需求，帮助他们完成指定任务。同时，社交聊天机器人还需要足够高的情商（EQ），以满足用户情感的需求，比如情绪感受和社会归属感。</p><ul><li><strong>IQ：</strong>IQ能力包括知识和记忆建模、图像和自然语言理解、推理生成和预测。为了满足用户的特定需求以及帮助用户完成指定的任务，这些能力是不可或缺的。其中最重要且最复杂的技能是核心聊天（Core Chat），即与用户在多个主题上展开长时间和开放域的对话</li><li><strong>EQ：</strong></li><li><strong>Personality：</strong>符合小冰既有的风格</li></ul><p><strong>将社交聊天视为分层决策</strong></p><p>对话可被视为有自然层级的决策过程：一个顶级过程管理者整体的对话并选取不同的技能来处理不同类型 的对话模式（比如闲聊、问答、订票）；低级过程则受所选择的技能控制。可选择基本动作（响应），从而生成对话段落或完成任务。</p><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><img src="https://cdn.nlark.com/yuque/0/2019/png/104214/1546398672251-b8e722bc-4c4f-4a68-b363-c5f85ec5269a.png" alt></p><p>上图为小冰的整体架构，其包含三层：用户体验层、对话引擎层和数据层。</p><h3 id="用户体验层"><a href="#用户体验层" class="headerlink" title="用户体验层"></a>用户体验层</h3><h3 id="对话引擎层"><a href="#对话引擎层" class="headerlink" title="对话引擎层"></a>对话引擎层</h3><p>对话引擎层中的四个主要组件：对话管理、共情计算、核心聊天和技能。</p><h4 id="对话管理"><a href="#对话管理" class="headerlink" title="对话管理"></a>对话管理</h4><p>对话管理除了记录<strong>对话历史</strong>还要包括策略管理，即管理什么时候触发Skill什么时候切换。同时，Conversation还受到Topic的管理。在Pretrain的阶段得到Topic Index，当触发Topic切换的标志时，例如：</p><ol><li>Core Chat未能生成有效的候选集</li><li>生成的响应知识用户输入的重复</li><li>用户输入变得平淡</li></ol><p>则调用Topic切换，切换之后的Topic根据以下几个指标选取：</p><ol><li>上下文关联性</li><li>新鲜度</li><li>个人兴趣</li><li>热度</li><li>接受度</li></ol><h4 id="共情计算（Empathetic-Computing）"><a href="#共情计算（Empathetic-Computing）" class="headerlink" title="共情计算（Empathetic Computing）"></a>共情计算（Empathetic Computing）</h4><p>共情度计算是小冰相对独特的一点，它不是直接把Context和Reply进行匹配得到一个Match Score。而是由Query, Context, Reply及情景分析得到一个$s=\left(Q_{c}, C, e_{Q}, e_{R}\right)$向量，再由向量$s$计算出候选回复。</p><p><strong>Contextual Query Understanding</strong></p><p>本模块的主要任务是对Context进行补全，通过命名实体识别和指代消解的方法，对对话历史信息进行补全。</p><p><strong>User Understand</strong></p><p><strong>Interpersonal Response Generation</strong></p><h4 id="核心聊天（Core-chat）"><a href="#核心聊天（Core-chat）" class="headerlink" title="核心聊天（Core chat）"></a>核心聊天（Core chat）</h4><p>核心聊天是小冰的<strong>智商</strong>和<strong>情商</strong>的重要组成部分。小冰在处理语言生成的时候使用两阶段法，先构造Reply候选集，然后通过计算每个Reply的得分（Score）选出最优答案。</p><p><img src="http://image.sherlocknlp.com/image/20190627/LYBy1QUaoGK4.png" alt="mark"></p><p><strong>Retrieval-Based Generator Using Paired Data</strong></p><p><strong>Neural Generate Generator</strong></p><p>单纯靠检索来获得数据，会漏掉一些新的热点，覆盖面不高。在小冰的架构中，对前面构造的向量$s$做sigmoid操作$v=\sigma\left(W_{Q}^{T} e_{Q}+W_{R}^{T} e_{R}\right)$，每一轮都喂到网络中这样保证了生成的Response带有小冰的<code>人格</code>。</p><p><strong>Retrieval-Based Generator Using Unpaired Data</strong></p><p><strong>Response Candidate Ranker</strong> </p><p><img src="http://image.sherlocknlp.com/image/20190705/GUwP0hormQJr.png" alt="mark"></p><h3 id="数据层"><a href="#数据层" class="headerlink" title="数据层"></a>数据层</h3><p><img src="http://image.sherlocknlp.com/image/20190627/ssSoBWfXdGoo.png" alt="mark"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://wyydsb.xin/" target="_blank" rel="noopener">直男届的杀手-『小冰』架构解析</a></p><p><a href="https://zhuanlan.zhihu.com/p/53667904" target="_blank" rel="noopener">沈向洋等人论文详解微软小冰，公开研发细节</a></p><p><a href="https://arxiv.org/pdf/1812.08989.pdf" target="_blank" rel="noopener">The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Li Zhou et al. 18.12</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/104214/1546396005189-1beef810-d825-4ea8-8597-3806892e92d4.png&quot; alt&gt;&lt;/p&gt;
&lt;h2 id=&quot;设计思想&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
      <category term="dialogue system" scheme="http://www.sherlocknlp.com/tags/dialogue-system/"/>
    
  </entry>
  
  <entry>
    <title>《通过对响应原型编辑的回复生成》阅读笔记</title>
    <link href="http://www.sherlocknlp.com/%E3%80%8A%E9%80%9A%E8%BF%87%E5%AF%B9%E5%93%8D%E5%BA%94%E5%8E%9F%E5%9E%8B%E7%BC%96%E8%BE%91%E7%9A%84%E5%9B%9E%E5%A4%8D%E7%94%9F%E6%88%90%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.sherlocknlp.com/《通过对响应原型编辑的回复生成》阅读笔记/</id>
    <published>2019-05-31T08:20:01.582Z</published>
    <updated>2019-07-03T08:46:39.911Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/JBLOFiIj98jN.png" alt="mark"></p><p>论文题目：<a href="https://arxiv.org/abs/1806.07042" target="_blank" rel="noopener">Response Generation by Context-aware Prototype Editing</a></p><p>代码链接：<a href="https://github.com/MarkWuNLP/ResponseEdit" target="_blank" rel="noopener">https://github.com/MarkWuNLP/ResponseEdit</a></p><p>AAAI 2019 北航</p><p>本文的<strong>主要目的</strong>是为了解决开放域对话生成中，生成句子较短且无意义的问题。模型首先从预定义的索引中检索到响应，然后根据问题原型和当前问题的差异编辑响应原型。主要思想是基于<strong>由于响应原型有很好的语法和信息，对响应原型进行轻微地调整就能得到较好的回复</strong>这一假设，来进行相关实验和论证。这是一种<strong>“检索+生成”</strong>的方法，既有检索式聊天机器人回复流畅和信息量大的优势，还有生成式聊天机器人的灵活性和相关性。</p><p><img src="http://ps1hmyafs.bkt.clouddn.com/FvX6HP7sPZxLKZp34lUpIRRdFkuq" alt></p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>该模型由原型选择器$\mathcal{S}$和上下文感知编辑器$\mathcal{E}$组成。给定一个新的会话，我们首先使用选择器S来检索语料$\mathcal{D} = {(C_i, R_i)}_{i=1}^{N}$中的$(C_{i}, R_{i}) \in \mathcal{D}$。然后编辑器$\mathcal{E}$计算出$z_i = f(C_i, C)$来编码$C_i$和$C$之间的差异信息。最后，通过概率$p(R|z_i, R_i)$生成回复。</p><p><img src="http://ps1hmyafs.bkt.clouddn.com/FjSHtNN5ZpLNsSmzX2LfHhPyJfUO" alt></p><h3 id="原型选择器-Prototype-Selector"><a href="#原型选择器-Prototype-Selector" class="headerlink" title="原型选择器(Prototype Selector)"></a>原型选择器(Prototype Selector)</h3><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/Bj1N1dPqytaM.png" alt="mark"></p><p>原型选择器使用<a href="https://lucenenet.apache.org/" target="_blank" rel="noopener">Lucene</a>框架用于检索，并应用其内置算法计算相似度。</p><p><strong>测试阶段</strong></p><p>根据上下文$C$与语料中$C^{‘}$的相似性选出（$C^{‘}$ , $R^{‘}$）</p><p><strong>训练阶段</strong></p><p>由于有真实的response，训练阶段的$C$，$R$对是通过response之间的相似性中选出来的。使用Jaccard相似度，取出范围在0.3-0.7的结果。这样既过滤掉相似度小于0.3的不相关回复，又除去相似度大于0.7的回复，避免直接copy。</p><p>Jaccard相似系数</p><script type="math/tex; mode=display">J(A, B) = \frac{|A \cap B|}{|A \cup B|}</script><p>在这个阶段最终得到多个四元组$(C, R, C^{‘}, R^{‘})$</p><h3 id="上下文感知编辑器（Context-Aware-Neural-Editor）"><a href="#上下文感知编辑器（Context-Aware-Neural-Editor）" class="headerlink" title="上下文感知编辑器（Context-Aware Neural Editor）"></a>上下文感知编辑器（Context-Aware Neural Editor）</h3><h4 id="Edit-Vector-Generation"><a href="#Edit-Vector-Generation" class="headerlink" title="Edit Vector Generation"></a>Edit Vector Generation</h4><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/i8r6XpJRkoB8.png" alt="mark"></p><p>该部分的主要功能是根据$C$和$C^{‘}$的差异生成编辑向量（edit vector）</p><p>用biGRU对$R^{‘}$进行编码</p><script type="math/tex; mode=display">\overrightarrow{h_j} = f_{GRU}(h_{j-1}, r_{j}^{'}); \overleftarrow{h_j} = f_{GRU}(h_{j+1}, r_{j}^{'})</script><p>用attention机制计算context之间的diff-vector，其中$I=\{w | w \in C \land w \notin C^{‘}\}$表示插入词集合，$I=\{D | w^{‘} \in C^{‘} \land w^{‘} \notin C \}$表示删除词集合，$\oplus$表示concat操作。</p><script type="math/tex; mode=display">diff_{c} = \sum_{w \in I} \beta_w \Psi(w) \oplus \sum_{w^{'} \in D} \gamma_{w^{'}} \Psi(w^{'})</script><script type="math/tex; mode=display">\beta_w = \frac{exp(e_w)}{\sum_{w \in I}exp(e_w)}</script><script type="math/tex; mode=display">e_w = v_{\beta}^{T}tanh(W_{\beta}[\Psi(w)\oplus h_l])</script><script type="math/tex; mode=display">\gamma_{w^{'}} = \frac{exp(e_{w^{'}})}{\sum_{w \in I}exp(e_{w^{'}})}</script><script type="math/tex; mode=display">z = tanh(W \cdot diff_{c} + b)</script><h4 id="Prototype-Editing"><a href="#Prototype-Editing" class="headerlink" title="Prototype Editing"></a>Prototype Editing</h4><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/TCjGFpwKUP4r.png" alt="mark"></p><p>该部分将编辑向量（edit vector）集成到decoder中进行输出</p><script type="math/tex; mode=display">h_{j}^{\prime}=f_{\mathrm{GRU}}\left(h_{j-1}^{\prime}, r_{j-1} \oplus z_{i}\right)</script><script type="math/tex; mode=display">c_{i}=\sum_{j=1}^{t} \alpha_{i, j} h_{j}</script><script type="math/tex; mode=display">\begin{aligned} \alpha_{i, j} &=\frac{\exp \left(e_{i, j}\right)}{\sum_{k=1}^{t} \exp \left(e_{i, k}\right)} \\ e_{i, j} &=\mathbf{v}^{\top} \tanh \left(\mathbf{W}_{\alpha}\left[h_{j} \oplus h_{i}^{\prime}\right]\right) \end{aligned}</script><script type="math/tex; mode=display">s\left(r_{i}\right)=\operatorname{softmax}\left(\mathbf{W}_{\mathbf{p}}\left[r_{i-1} \oplus h_{i}^{\prime} \oplus c_{i}\right]+\mathbf{b}_{\mathbf{p}}\right)</script><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><script type="math/tex; mode=display">\mathcal{L} = - \sum_{i=1}^N\sum_{j=1}^{l}log p(r_{i,j}|z_i, R_{i}^{'}, r_i, k<j)</script><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>实验中去掉了长于30个词的context-response对，2000W训练集，1W开发集，1W测试集。</p><p>optimizer: Adam</p><p>batch size: 128</p><p>learning rate: 0.001 </p><p>复杂度连续两个epoch增加就停止训练</p><h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><p>S2SA: Seq2Seq with attention</p><p>S2SA-MMI：bidirectional-MMI</p><p>CVAE:</p><p>Retrieval-default: Luence</p><p>Retrieval-Rerank: dual-LSTM</p><p>Ensemble:  </p><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/b5a8kWcFkUVR.png" alt="mark"></p><h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/fApi1vQh1WLv.png" alt="mark"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文针对开放领域回复生成（闲聊）提出了一个先检索<strong>“原型”</strong>再<strong>“编辑”</strong>的范式。以后的工作可能会联合训练<strong>prototype selector</strong>和<strong>neural editor</strong>两个部分。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;http://ps1hmyafs.bkt.clouddn.com/image/20190531/JBLOFiIj98jN.png&quot; alt=&quot;mark&quot;&gt;&lt;/p&gt;
&lt;p&gt;论文题目：&lt;a href=&quot;https://arxiv.org/abs/1806.0
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
      <category term="NLG" scheme="http://www.sherlocknlp.com/categories/NLP/NLG/"/>
    
    
      <category term="dialogue system" scheme="http://www.sherlocknlp.com/tags/dialogue-system/"/>
    
  </entry>
  
  <entry>
    <title>Attention模型方法综述</title>
    <link href="http://www.sherlocknlp.com/Attention%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0%EF%BC%88%E5%A4%9A%E7%AF%87%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%EF%BC%89/"/>
    <id>http://www.sherlocknlp.com/Attention模型方法综述（多篇经典论文解读）/</id>
    <published>2019-05-30T01:54:37.653Z</published>
    <updated>2019-09-15T13:24:45.324Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Attention背景介绍"><a href="#Attention背景介绍" class="headerlink" title="Attention背景介绍"></a>Attention背景介绍</h1><p><img src="https://note.youdao.com/yws/api/personal/file/A55104E9C80C40F1B77C0D20B8D97A18?method=download&amp;shareKey=83583c4427a6e2c50acad2d37b9f8098" alt="cat"></p><p>先简单谈一谈attention模型的引入。以基于seq2seq模型的机器翻译为例，如果decoder只用encoder最后一个时刻输出的hidden state,可能会有<strong>两个问题</strong>。</p><ol><li>encoder最后一个hidden state, 与句子末端词汇的关联较大，难以保留句子起始部分的信息；</li><li>encoder按顺序依次接受输入，可以认为encoder产出的hidden state包含词序信息。所以一定程度上decoder的翻译也会按照原始句子的书序依次进行，但实际中翻译却未必如此。</li></ol><p>为了一定程度上解决以上的问题，14年的一篇文章Sequence to Sequence Learning with Neural Network提出了一个有意思的trick，即在模型训练的过程中将原始句子进行反转，取得了一定的效果。</p><p>在计算Attention时主要分三步，<strong>第一步</strong>是将query和每个key进行相似度计算得到权重，常用的相似度函数有<strong>点积、拼接和感知机等</strong>；<strong>第二步</strong>使用softmax函数对这些权重进行归一化；第三步将权重和相应的键值进行加权求和得到最后的attention。</p><script type="math/tex; mode=display">f(Q, K_j) = \begin{cases} Q^T K_j, & \text {dot} \\ Q^T W_a K_j, & \text {general} \\ W_a[Q,K_j], & \text concat \\v_a^Ttanh(W_a[h_t;\tilde{h}_s]) & \text {perceptron} \end{cases}</script><script type="math/tex; mode=display">\alpha_j = softmax(f(Q,K_j)) = \frac {exp(f(Q,K_j))}{\sum_j exp(f(Q, K_j))}</script><script type="math/tex; mode=display">Attention(Q,K,V) = \sum_j \alpha_j V_j</script><h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><p>Attention机制的本质来自于人类视觉注意力机制。</p><h2 id="Show-Attend-and-Tell（Soft-Hard-Attention）"><a href="#Show-Attend-and-Tell（Soft-Hard-Attention）" class="headerlink" title="Show, Attend and Tell（Soft/Hard Attention）"></a>Show, Attend and Tell（Soft/Hard Attention）</h2><p>■ 论文 | <a href>Effective Approaches to Attention-based Neural Machine Translation</a></p><p>■ 源码 | <a href="https://github.com/kelvinxu/arctic-captions" target="_blank" rel="noopener">https://github.com/kelvinxu/arctic-captions</a></p><p>文章中提出了两种attention模式，即<strong>hard attention</strong>和<strong>soft attention</strong>。</p><p>这是对attention的另一种分类。Soft attention本质上和Bahdanau提出的很相似，其权重取值在0到1之间，而Hard Attention取值0或者1。<strong>hard attention专注于很小的区域，而soft attention的注意力相对发散。</strong> </p><p><img src="http://ps1hmyafs.bkt.clouddn.com/image/20190531/bhoyik1kWbKt.png" alt="mark"></p><h2 id="Attention-based-NMT"><a href="#Attention-based-NMT" class="headerlink" title="Attention-based NMT"></a>Attention-based NMT</h2><p><img src="https://note.youdao.com/yws/api/personal/file/F761136507CB4D248E3FFC6CE5F9F4BA?method=download&amp;shareKey=733e71450c39674c12a6ea371be49ac5" alt></p><p><img src="https://note.youdao.com/yws/api/personal/file/40FBFDA54DB448C2BD65664F225D5095?method=download&amp;shareKey=28e5db4f38acdcddbc0cf66c37bbea00" alt="NMT-paper"></p><p>■ 论文 | <a href>Effective Approaches to Attention-based Neural Machine Translation</a></p><p>■ 源码 | <a href="https://github.com/lmthang/nmt.matlab" target="_blank" rel="noopener">https://github.com/lmthang/nmt.matlab</a></p><p>这篇论文是继上一篇论文之后，一篇很具代表性的论文。他们的工作告诉了大家attention在RNN中可以如何进行扩展，这篇论文对后续各种基于attention的模型在NLP的应用起到很大的促进作用。在论文中她们提出了两种attention机制，一种是<strong>全局（global）机制</strong>，一种<strong>是局部（local）机制</strong>。</p><p>在decoder的第t时刻，利用global attention或local attention得到context vector($c_t$)之后，对$h_t$和$c_t$进行concatenate操作得到attention hidden state。</p><script type="math/tex; mode=display">\tilde{h}_t = tanh(W_c[c_t;h_t])</script><p>最后利用softmax产出该时刻的输出：</p><script type="math/tex; mode=display">p(y_t|y_{<t}, x) = softmax(W_s\tilde{h}_t)</script><h3 id="global-attention"><a href="#global-attention" class="headerlink" title="global attention"></a>global attention</h3><p><img src="https://note.youdao.com/yws/api/personal/file/462AD3AE189E4F35BA83B4B83A60AEF7?method=download&shareKey=fe16c34653a1c582839dd73d371b60a9" width="800" hegiht="313" align="right"></p><p>global attention在计算context vector($c_t$)的时候会考虑encoder所产生的全部hidden state。记decoder时刻t的target hidden为$h_t$，encoder的全部hidden state为$\tilde{h}_s, s =1,2,…,n$。对其中任意$\tilde{h}_s$,其权重$\alpha_t(s)$为：</p><script type="math/tex; mode=display">\alpha_t(s) = align(h_t, \tilde{h}_s) = \frac {exp(score(h_t,\tilde{h}_s))}{\sum_{s^`} exp(score(h_t, \tilde{h}_{s^`}))}</script><p>其中的$score(h_t,\tilde{h}_s)$的计算方法如下</p><script type="math/tex; mode=display">score(h_t, \tilde{h}_s) = \begin{cases} h_t^T \tilde{h}_s, & \text {dot} \\ h_t^TW_a\tilde{h}_s, & \text {general} \\ v_a^Ttanh(W_a[h_t;\tilde{h}_s]) & \text {concat} \end{cases}</script><h3 id="local-attention"><a href="#local-attention" class="headerlink" title="local attention"></a>local attention</h3><p><img src="https://note.youdao.com/yws/api/personal/file/8CAAE42558054608BF224D46B141F206?method=download&shareKey=2a379ba8c7cc1cfefd8babc86455c4db" width="800" hegiht="313" align="right"></p><p>global attention可能的缺点在于每次都要扫描全部的source hidden state，计算开销较大，对于长句翻译不利。为了提升效率，提出的local attention每次只focus一小部分的source position。</p><h2 id="NMT-by-Joint-Learning"><a href="#NMT-by-Joint-Learning" class="headerlink" title="NMT by Joint Learning"></a>NMT by Joint Learning</h2><p>■ 论文 | <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></p><p>■ 源码 | <a href="https://github.com/spro/torch-seq2seq-attention" target="_blank" rel="noopener">https://github.com/spro/torch-seq2seq-attention</a></p><h2 id="Attention-is-All-You-Need"><a href="#Attention-is-All-You-Need" class="headerlink" title="Attention is All You Need"></a>Attention is All You Need</h2><p>■ 论文 | <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention is All You Need</a></p><p>■ 源码 | <a href="https://github.com/Kyubyong/transformer" target="_blank" rel="noopener">https://github.com/Kyubyong/transformer</a></p><p>本文提出了一种新型的网络结构，并起名叫做Transformer，里面所包含的注意力机制称为self-attention。</p><p><img src="https://note.youdao.com/yws/api/personal/file/F5FFA65439514F5E8B3DEE2FEA8103A7?method=download&amp;shareKey=8a10d97f7027f0cbb0d98bf6e5c713b2" alt="transformer"></p><p><img src="https://note.youdao.com/yws/api/personal/file/A7564168106A4456B7FA574EAD166CC6?method=download&amp;shareKey=2bcff76457eaecdc785cd830972eba21" alt></p><h3 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h3><p><img src="https://note.youdao.com/yws/api/personal/file/75B2600C41E24392A547E86F1EB14BCE?method=download&amp;shareKey=5824b4c2e293e04068dd3e8121bfa0c0" alt></p><script type="math/tex; mode=display">Attention(Q,K,V) = softmax\left(\frac {QK^T} {\sqrt{d_k}}\right)VQ \in R^{n\times d_k}, K\in R^{m\times d_k}, V\in R^{m\times d_v}</script><p>如果忽略softmax函数，上述公式可以看作三个维数为$n\times d_k,d_k \times m, m\times d_v$的矩阵相乘，最后得到一个$n\times d_v$的矩阵。因此，该Attention层就可以看作，将维数为<code>$n\times d_k$</code>的序列Q编码成一个维数为$n\times d_v$的序列。</p><h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p><img src="https://note.youdao.com/yws/api/personal/file/015E714496024CBA90313426A933F7A7?method=download&amp;shareKey=fa4dcdc4650aa588b157f4aab5e518c6" alt></p><script type="math/tex; mode=display">head_i = Attention(QW_i^Q, KW_i^Q, VW_i^V)</script><script type="math/tex; mode=display">MultiHead(Q,K,V) = Concat(head_1, ..., head_h)</script><p>本文主要的贡献之一是<strong>它表明了内部注意力机制在机器翻译（甚至是一般的Seq2Seq任务）的序列编码上很重要</strong>。Multi-Head Self-Attention不是仅仅计算一次注意力，而是多次并行地计算Scaled dot-product attention，所有的注意力结果级联后经线性变换到预期的维度。</p><h3 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h3><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247486960&amp;idx=1&amp;sn=1b4b9d7ec7a9f40fa8a9df6b6f53bbfb&amp;chksm=96e9d270a19e5b668875392da1d1aaa28ffd0af17d44f7ee81c2754c78cc35edf2e35be2c6a1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂「Attention is All You Need」- 苏剑林</a></p><p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></p><p><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Attention背景介绍&quot;&gt;&lt;a href=&quot;#Attention背景介绍&quot; class=&quot;headerlink&quot; title=&quot;Attention背景介绍&quot;&gt;&lt;/a&gt;Attention背景介绍&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://note.you
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
  </entry>
  
  <entry>
    <title>知识驱动的对话生成</title>
    <link href="http://www.sherlocknlp.com/%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E5%AF%B9%E8%AF%9D/"/>
    <id>http://www.sherlocknlp.com/知识驱动对话/</id>
    <published>2019-05-26T03:24:17.767Z</published>
    <updated>2019-07-04T11:06:32.466Z</updated>
    
    <content type="html"><![CDATA[<p>该任务是基于<a href="http://lic2019.ccf.org.cn/" target="_blank" rel="noopener">2019年语言与智能竞赛</a>，知识驱动对话赛道。当前聊天机器人不够主动，并且回复信息不够丰富。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>给定目标 $g$ 及相关知识信息 $M=f_1, f_2, …, f_n$ ，要求参评的对话系统输出适用于当前新对话序列 $H=u_1, u_2,…,u_{t-1}$ 的机器回复$u_t$使得对话自然流畅、信息丰富而且符合对话目标的规划。在对话过程中，机器处于主动状态，引导用户从一个话题聊到另一个话题。因此，对话系统为机器设定了一个对话目标，$g$为<strong>“START-&gt;TOPIC_A-&gt;TOPIC_B”</strong>，表示从冷启动状态主动聊到话题A，然后进一步聊到话题B。</p><h2 id="比赛数据"><a href="#比赛数据" class="headerlink" title="比赛数据"></a>比赛数据</h2><p>数据中的知识信息来源于电影和娱乐人物领域有价值的信息，如票房、导演、评价等，以三元组SPO的形式组织。对话目标中的话题为电影或娱乐人物实体，数据集中共有3万session，大约12万轮对话，其中10万训练集，1万开发集，1万测试集。</p><p><img src="https://i.loli.net/2019/04/30/5cc7bcb33dbac.jpg" alt="d83d4989ly1g2difnecrtj20sv0gogs7.jpg"></p><h2 id="基线模型"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型</h2><p>该模型主要由四部分组成，分别为对话内容编码器、知识编码器、知识管理器和解码器。</p><p>paper:  <a href="https://arxiv.org/abs/1902.04911" target="_blank" rel="noopener">https://arxiv.org/abs/1902.04911</a></p><p>code: <a href="https://github.com/baidu/knowledge-driven-dialogue" target="_blank" rel="noopener">https://github.com/baidu/knowledge-driven-dialogue</a></p><p><img src="https://i.loli.net/2019/04/30/5cc7bd67a99db.jpg" alt="d83d4989ly1g2did035ahj20kv0d6wge.jpg"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>在这部分，模型使用双向GRU来对<code>对话内容</code>和<code>知识</code>进行编码。我们定义$X$为多轮对话内容，$K$为知识库信息，$Y$为真实的回复。编码器将对话内容 $X$ 和知识信息 $K$ 编码成向量 $x$ 和 $k$，之后送入<strong>Knowledge manager</strong>。编码对话内容和知识信息的两个编码器遵循同样的结构，但不共享参数。</p><script type="math/tex; mode=display">h_t =[\overrightarrow{h}_t ; \overleftarrow{h}_t]=[GRU(x_t, \overrightarrow{h}_{t-1});GRU(x_t, \overleftarrow{h}_{t+1})]</script><h3 id="Knowledge-Manager"><a href="#Knowledge-Manager" class="headerlink" title="Knowledge Manager"></a>Knowledge Manager</h3><p>知识管理模块这部分的作用主要为从外部知识中选出所需知识。在训练过程中，X和Y均被模型作为输入进行训练。这是通过后验信息得到知识的概率分布，计算公式如下：</p><script type="math/tex; mode=display">p(k=k_i |x,y)=\frac{exp(k_i \cdot MLP([x;y]))}{\sum_{j=1}^{N} exp(ki \cdot MLP([x;y]))}</script><p>但在生成预测回复的时候，$Y$对于我们来说是未知的，所以我们只能通过输入$X$来进行知识选择。具体公式如下：</p><script type="math/tex; mode=display">p(k=k_i|x)=\frac{exp(k_i \cdot x)}{\sum_{j=1}^N exp(k_j \cdot x)}</script><p>在训练和预测回复的过程中，选择知识$k$分别是依据后验概率$p(k|x,y)$和$p(k|x)$。因此知识管理模块采用KLDivLoss（KullbackLeibler divergence loss）作为损失函数来衡量先验和后验的相似性。</p><script type="math/tex; mode=display">\mathcal{L}_{KL}(\theta)=-\frac{1}{N}\sum_{i=1}^{N}p(k=k_i|x,y)log\frac{p(k=k_i|x,y)}{p(k=k_i|x)}</script><h3 id="Knowledge-Manager-1"><a href="#Knowledge-Manager-1" class="headerlink" title="Knowledge Manager"></a>Knowledge Manager</h3><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>在上下文内容$c_t$和所选择的$k_i$的条件下，模型的解码器按顺序生成回复。与传统的Seq2Seq解码器不同，该模型将知识融入到回复生成中。因此，模型中介绍两种解码器。</p><p><strong>Standard GRU with Concatenated Inputs</strong></p><p>$s_{t-1}$是GRU的上一步隐层状态，$c_t$是基于attention的上下文向量。</p><script type="math/tex; mode=display">s_t = GRU([y_{t-1};k_i], s_{t-1}, c_t)</script><p><strong>Hierarchical Gated Fusion Unit</strong></p><p>HGFU(Hierarchical Gated Fusion Unit)的中文是分级门控融合单元，其提供了一个相对较“软”的方法将Knowledge合并到回复当中。它主要由3部分组成：utterance GRU、knowledge GRU和fusion unit。</p><p>utterance GRU和knowledge GRU这两部分，均使用标准的GRU结构：</p><script type="math/tex; mode=display">s_t^y = GRU(y_{t-1}, s_{t-1}, c_t)</script><script type="math/tex; mode=display">s_t^k = GRU(k_{i}, s_{t-1}, c_t)</script><p>然后fusion unit将两个隐藏层合并起来生成解码器$t$时刻的隐藏状态。</p><script type="math/tex; mode=display">s_t = r \odot s_t^y + (1-r)\odot s_t^k</script><p>其中，$r$控制着隐层状态$s_t$的分布</p><script type="math/tex; mode=display">r = \sigma(W_z[tanh(W_y s_t^y);tanh(W_k s_t^k)])</script><h3 id="Loss-函数"><a href="#Loss-函数" class="headerlink" title="Loss 函数"></a>Loss 函数</h3><p>除了KLDivLoss以外，模型中的loss函数还包括NLL Loss和BOW Loss。其中，NLL Loss的作用是最小化生成回复与原始回复之间的差异：</p><script type="math/tex; mode=display">\mathcal{L}_{NLL}(\theta)=-\frac{1}{m} \sum_{t=1}^{m} log p_{\theta}(y_t|y<t, x, k_i)</script><p>BOW Loss函数的作用是保证生成的回复和知识之间的相关性</p><script type="math/tex; mode=display">p_{\theta}(y_t|k_i)=\frac{exp(w_{y_t})}{\sum_{v \in V} exp(w_{\theta})}</script><script type="math/tex; mode=display">\mathcal{L}_{BOW}(\theta) = - \frac{1}{m}\sum_{t=1}{m} logp_{\theta}(y_t|k_i)</script><p>因此，该模型的综合损失函数为：</p><script type="math/tex; mode=display">\mathcal{L}(\theta) = \mathcal{L}_{KL}(\theta)+\mathcal{L}_{NLL}(\theta)+\mathcal{L}_{BOW}(\theta)</script><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="自动评价指标"><a href="#自动评价指标" class="headerlink" title="自动评价指标"></a>自动评价指标</h3><ul><li>F1：评估输出回复相对于标准回复在自己别上的准确召回性能，是评估模型性能的主要指标；</li><li>BLEU：评估输出回复相对于标准回复在词级别上的性能，是评估模型性能的辅助指标；</li><li>DISTINCT：评估输出回复的多样性，是评估模型性能的辅助指标；</li></ul><h3 id="人工评价"><a href="#人工评价" class="headerlink" title="人工评价"></a>人工评价</h3><p>人工评估从流畅性、一致性和主动性等几个维度进行评估。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;该任务是基于&lt;a href=&quot;http://lic2019.ccf.org.cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2019年语言与智能竞赛&lt;/a&gt;，知识驱动对话赛道。当前聊天机器人不够主动，并且回复信息不够丰富。&lt;/p&gt;
&lt;h2 id=&quot;任
      
    
    </summary>
    
      <category term="NLP" scheme="http://www.sherlocknlp.com/categories/NLP/"/>
    
    
      <category term="dialogue system" scheme="http://www.sherlocknlp.com/tags/dialogue-system/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.sherlocknlp.com/hello-world/"/>
    <id>http://www.sherlocknlp.com/hello-world/</id>
    <published>2019-04-08T03:05:45.217Z</published>
    <updated>2019-04-08T03:05:45.217Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
